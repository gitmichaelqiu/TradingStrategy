{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310fc6bf",
   "metadata": {},
   "source": [
    "# AdaptiveRegimeStrategy V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4be3e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from abc import ABC, abstractmethod\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db667cc",
   "metadata": {},
   "source": [
    "## Feature Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "14adbb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLab:\n",
    "    \"\"\"Shared mathematical engine for technical and statistical features.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_weights_frac_diff(d, size, threshold=1e-5):\n",
    "        w = [1.0]\n",
    "        for k in range(1, size):\n",
    "            w_k = -w[-1] / k * (d - k + 1)\n",
    "            w.append(w_k)\n",
    "        w = np.array(w[::-1])\n",
    "        w = w[np.abs(w) > threshold]\n",
    "        return w\n",
    "\n",
    "    @staticmethod\n",
    "    def frac_diff_fixed(series, d, window=50):\n",
    "        # Solves Stationarity Dilemma [cite: 61]\n",
    "        weights = FeatureLab.get_weights_frac_diff(d, window)\n",
    "        res = series.rolling(window=len(weights)).apply(lambda x: np.dot(x, weights), raw=True)\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def yang_zhang_volatility(df, window=30):\n",
    "        # Captures intraday energy/gaps [cite: 82]\n",
    "        log_ho = (df['High'] / df['Open']).apply(np.log)\n",
    "        log_lo = (df['Low'] / df['Open']).apply(np.log)\n",
    "        log_co = (df['Close'] / df['Open']).apply(np.log)\n",
    "        log_oc = (df['Open'] / df['Close'].shift(1)).apply(np.log)\n",
    "        log_cc = (df['Close'] / df['Close'].shift(1)).apply(np.log)\n",
    "        \n",
    "        rs = log_ho * (log_ho - log_co) + log_lo * (log_lo - log_co)\n",
    "        close_vol = log_cc.rolling(window=window).var()\n",
    "        open_vol = log_oc.rolling(window=window).var()\n",
    "        window_rs = rs.rolling(window=window).mean()\n",
    "\n",
    "        k = 0.34 / (1.34 + (window + 1) / (window - 1))\n",
    "        return np.sqrt(open_vol + k * window_rs)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_rsi(series, window=14):\n",
    "        delta = series.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rs = gain / loss\n",
    "        return 100 - (100 / (1 + rs))\n",
    "\n",
    "    @staticmethod\n",
    "    def triple_barrier_labels(prices, vol, pt=1.0, sl=1.0, barrier_window=10):\n",
    "        \"\"\"\n",
    "        Implements the Triple Barrier Method.\n",
    "        Labels: 1 (Profit Target Hit), -1 (Stop Loss Hit), 0 (Time Limit/Neutral)\n",
    "        \"\"\"\n",
    "        labels = pd.Series(0, index=prices.index)\n",
    "        # Shift prices to align future outcome with current row\n",
    "        # However, to avoid look-ahead in features, we usually compute label for row t based on t+1...t+k\n",
    "        # This function generates the TARGET variable (y) for training.\n",
    "        \n",
    "        limit = len(prices) - barrier_window\n",
    "        p_values = prices.values\n",
    "        v_values = vol.values\n",
    "        \n",
    "        for i in range(limit):\n",
    "            current_p = p_values[i]\n",
    "            current_vol = v_values[i]\n",
    "            \n",
    "            # Dynamic barriers based on volatility [cite: 215]\n",
    "            target = current_p * (1 + pt * current_vol)\n",
    "            stop = current_p * (1 - sl * current_vol)\n",
    "            \n",
    "            future_window = p_values[i+1 : i+1+barrier_window]\n",
    "            \n",
    "            hit_target = np.where(future_window >= target)[0]\n",
    "            hit_stop = np.where(future_window <= stop)[0]\n",
    "            \n",
    "            first_target = hit_target[0] if len(hit_target) > 0 else barrier_window + 1\n",
    "            first_stop = hit_stop[0] if len(hit_stop) > 0 else barrier_window + 1\n",
    "            \n",
    "            if first_target < first_stop and first_target <= barrier_window:\n",
    "                labels.iloc[i] = 1\n",
    "            elif first_stop < first_target and first_stop <= barrier_window:\n",
    "                labels.iloc[i] = 0 # In Meta-Labeling, we often treat Stop (-1) as 0 (Do Not Trade)\n",
    "            # Else 0 (Time limit reached or neutral)\n",
    "            \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381033d7",
   "metadata": {},
   "source": [
    "## Base Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5398e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStrategy(ABC):\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        self.ticker = ticker\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.data = None\n",
    "        self.results = None\n",
    "        self.metrics = {}\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\")\n",
    "        warmup_start_dt = start_dt - timedelta(days=warmup_years*365)\n",
    "        warmup_start_str = warmup_start_dt.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        try:\n",
    "            self.data = yf.download(self.ticker, start=warmup_start_str, end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(self.data.columns, pd.MultiIndex): \n",
    "                self.data.columns = self.data.columns.get_level_values(0)\n",
    "            if 'Adj Close' not in self.data.columns: \n",
    "                self.data['Adj Close'] = self.data['Close']\n",
    "            self.data['Returns'] = self.data['Adj Close'].pct_change()\n",
    "            self.data.dropna(inplace=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {self.ticker}: {e}\")\n",
    "            self.data = pd.DataFrame()\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_signals(self):\n",
    "        pass\n",
    "\n",
    "    def run_backtest(self, transaction_cost=0.0005, rebalance_threshold=0.1):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        \n",
    "        backtest_mask = self.data.index >= self.start_date\n",
    "        df = self.data.loc[backtest_mask].copy()\n",
    "        if df.empty: return\n",
    "\n",
    "        # Position Smoothing\n",
    "        clean_positions = []\n",
    "        current_pos = 0.0\n",
    "        raw_signals = df['Signal'].values\n",
    "        \n",
    "        for target in raw_signals:\n",
    "            if abs(target - current_pos) > rebalance_threshold:\n",
    "                current_pos = target\n",
    "            clean_positions.append(current_pos)\n",
    "            \n",
    "        df['Position'] = clean_positions\n",
    "        df['Prev_Position'] = df['Position'].shift(1).fillna(0)\n",
    "        df['Turnover'] = (df['Prev_Position'] - df['Position'].shift(2).fillna(0)).abs()\n",
    "        df['Gross_Returns'] = df['Prev_Position'] * df['Returns']\n",
    "        df['Net_Returns'] = df['Gross_Returns'] - (df['Turnover'] * transaction_cost)\n",
    "        df['Net_Returns'].fillna(0, inplace=True)\n",
    "        \n",
    "        df['Cumulative_Strategy'] = (1 + df['Net_Returns']).cumprod()\n",
    "        df['Cumulative_Market'] = (1 + df['Returns']).cumprod()\n",
    "        \n",
    "        roll_max = df['Cumulative_Strategy'].cummax()\n",
    "        df['Drawdown'] = (df['Cumulative_Strategy'] / roll_max) - 1.0\n",
    "        \n",
    "        self.results = df\n",
    "        \n",
    "        # Performance Calculation\n",
    "        total_ret = df['Cumulative_Strategy'].iloc[-1] - 1\n",
    "        vol = df['Net_Returns'].std() * np.sqrt(252)\n",
    "        sharpe = (df['Net_Returns'].mean() / df['Net_Returns'].std()) * np.sqrt(252) if vol > 0 else 0\n",
    "        max_dd = df['Drawdown'].min()\n",
    "        \n",
    "        self.metrics = {\n",
    "            'Total Return': total_ret,\n",
    "            'Sharpe Ratio': sharpe,\n",
    "            'Max Drawdown': max_dd\n",
    "        }\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cee99",
   "metadata": {},
   "source": [
    "## Model From NB V1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0ccb4",
   "metadata": {},
   "source": [
    "### V1_Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "93a7c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV1_Baseline(BaseStrategy):\n",
    "    \"\"\"V1: Fixed FracDiff, Standard GMM.\"\"\"\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['FracDiff'] = FeatureLab.frac_diff_fixed(df['Adj Close'].apply(np.log), d=0.4, window=50)\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df['Returns_Smoothed'] = df['Returns'].rolling(5).mean()\n",
    "        df['Vol_Smoothed'] = df['Volatility'].rolling(5).mean()\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        X = df[['Returns_Smoothed', 'Vol_Smoothed']].values\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "        df['Cluster'] = gmm.fit_predict(X_scaled)\n",
    "        \n",
    "        stats = df.groupby('Cluster')['Returns_Smoothed'].mean().sort_values().index\n",
    "        mapping = {stats[0]: -1, stats[1]: 0, stats[2]: 1}\n",
    "        df['Regime'] = df['Cluster'].map(mapping)\n",
    "        \n",
    "        df['Signal'] = 0\n",
    "        df.loc[(df['Regime'] == 1) & (df['FracDiff'] > 0), 'Signal'] = 1\n",
    "        df.loc[(df['Regime'] == 0) & (df['RSI'] < 40), 'Signal'] = 1\n",
    "        \n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Vol_Scaler'] = (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        df['Signal'] = df['Signal'] * df['Vol_Scaler']\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529bcb35",
   "metadata": {},
   "source": [
    "### V3_Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9445384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV3_Macro(BaseStrategy):\n",
    "    \"\"\"V3: Macro (SPY) Filter.\"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.spy_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        super().fetch_data(warmup_years)\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\") - timedelta(days=warmup_years*365)\n",
    "        try:\n",
    "            spy = yf.download(\"SPY\", start=start_dt.strftime(\"%Y-%m-%d\"), end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(spy.columns, pd.MultiIndex): spy.columns = spy.columns.get_level_values(0)\n",
    "            self.spy_data = spy[['Adj Close']].rename(columns={'Adj Close': 'SPY_Price'})\n",
    "        except: pass\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        if self.spy_data is not None:\n",
    "            df = df.join(self.spy_data, how='left')\n",
    "            df['SPY_MA200'] = df['SPY_Price'].rolling(window=200).mean()\n",
    "            df['Macro_Bull'] = df['SPY_Price'] > df['SPY_MA200']\n",
    "        else:\n",
    "            df['Macro_Bull'] = True\n",
    "            \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['FracDiff'] = FeatureLab.frac_diff_fixed(df['Adj Close'].apply(np.log), d=0.4, window=50)\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        df['Signal'] = 0\n",
    "        df.loc[(df['FracDiff'] > 0), 'Signal'] = 1\n",
    "        df.loc[df['Macro_Bull'] == False, 'Signal'] = 0\n",
    "        \n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Signal'] = df['Signal'] * (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b77a15c",
   "metadata": {},
   "source": [
    "### V9_Unshackled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6e2ad3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV9_RegimeUnshackled(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V9 (Robust): The 'Unshackled' Regime Model with Walk-Forward Learning.\n",
    "    \n",
    "    CRITICAL FIX:\n",
    "    - Replaces static gmm.fit_predict() with a Rolling Walk-Forward loop.\n",
    "    - Eliminates Look-Ahead Bias by retraining the regime model every month\n",
    "      using only the trailing 1-year window.\n",
    "    - Solves the 'Label Switching' problem dynamically at each step.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.spy_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        super().fetch_data(warmup_years)\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\") - timedelta(days=warmup_years*365)\n",
    "        try:\n",
    "            # Fetch Macro Context (SPY) for the 'Alpha Clause'\n",
    "            spy = yf.download(\"SPY\", start=start_dt.strftime(\"%Y-%m-%d\"), end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(spy.columns, pd.MultiIndex): spy.columns = spy.columns.get_level_values(0)\n",
    "            \n",
    "            # Simple Macro Trend (200 SMA)\n",
    "            spy['Macro_Trend'] = (spy['Adj Close'] > spy['Adj Close'].rolling(200).mean()).astype(int)\n",
    "            self.spy_data = spy[['Macro_Trend']]\n",
    "        except: \n",
    "            pass\n",
    "\n",
    "    def _apply_kalman_filter(self, prices):\n",
    "        # [cite: 151] Kalman Filter for recursive state estimation\n",
    "        x = prices.values\n",
    "        n = len(x)\n",
    "        state = np.zeros(n)\n",
    "        slope = np.zeros(n)\n",
    "        state[0] = x[0]\n",
    "        P, Q, R = 1.0, 0.001, 0.1 # Static params for robustness\n",
    "        \n",
    "        for t in range(1, n):\n",
    "            pred_state = state[t-1] + slope[t-1]\n",
    "            pred_P = P + Q\n",
    "            measurement = x[t]\n",
    "            residual = measurement - pred_state\n",
    "            \n",
    "            K = pred_P / (pred_P + R)\n",
    "            state[t] = pred_state + K * residual\n",
    "            slope[t] = 0.9 * slope[t-1] + 0.1 * (state[t] - state[t-1])\n",
    "            P = (1 - K) * pred_P\n",
    "            \n",
    "        return pd.Series(slope, index=prices.index)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # --- 1. Feature Engineering ---\n",
    "        if self.spy_data is not None:\n",
    "            df = df.join(self.spy_data, how='left').fillna(method='ffill')\n",
    "        else: \n",
    "            df['Macro_Trend'] = 1\n",
    "            \n",
    "        # Volatility & Kalman Slope [cite: 82, 151]\n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['Kalman_Slope'] = self._apply_kalman_filter(np.log(df['Adj Close']))\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        \n",
    "        # Features for GMM (Smoothed to reduce noise)\n",
    "        df['Returns_Smoothed'] = df['Returns'].rolling(5).mean()\n",
    "        df['Vol_Smoothed'] = df['Volatility'].rolling(5).mean()\n",
    "        \n",
    "        # Drop NaN from warmup\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # --- 2. Rolling Walk-Forward GMM ---\n",
    "        # We need to predict 'Regime_Type' for every row without looking ahead.\n",
    "        \n",
    "        train_window = 252  # Lookback: 1 Year\n",
    "        refit_step = 21     # Re-train every Month\n",
    "        \n",
    "        # Initialize default regime (CHOP)\n",
    "        df['Regime_Type'] = 'CHOP' \n",
    "        \n",
    "        # Prepare Feature Matrix\n",
    "        X = df[['Returns_Smoothed', 'Vol_Smoothed']].values\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        indices = np.arange(len(df))\n",
    "        \n",
    "        # Start loop after the first training window\n",
    "        for t in range(train_window, len(df), refit_step):\n",
    "            start_idx = t - train_window\n",
    "            end_idx = t\n",
    "            predict_end_idx = min(t + refit_step, len(df))\n",
    "            \n",
    "            # A. Train on PAST window\n",
    "            X_train = X[start_idx:end_idx]\n",
    "            \n",
    "            # Scale locally (Standardization must also be walk-forward)\n",
    "            #  \"Standard algorithms assume training data... same probability distribution\"\n",
    "            scaler_local = StandardScaler()\n",
    "            X_train_scaled = scaler_local.fit_transform(X_train)\n",
    "            \n",
    "            try:\n",
    "                # Fit GMM\n",
    "                gmm = GaussianMixture(n_components=3, random_state=42, n_init=5)\n",
    "                gmm.fit(X_train_scaled)\n",
    "                \n",
    "                # B. Predict on NEXT window (Future)\n",
    "                X_future = X[end_idx:predict_end_idx]\n",
    "                X_future_scaled = scaler_local.transform(X_future)\n",
    "                clusters_future = gmm.predict(X_future_scaled)\n",
    "                \n",
    "                # C. Dynamic Label Mapping (Solve Label Switching)\n",
    "                # We map clusters to Bull/Bear based on the *Training* means\n",
    "                # Calculate mean return for each cluster center in the training set\n",
    "                # We can approximate this by predicting the training set again\n",
    "                train_clusters = gmm.predict(X_train_scaled)\n",
    "                \n",
    "                # Create a temp dataframe to sort clusters\n",
    "                temp_df = pd.DataFrame({\n",
    "                    'Ret': X_train[:, 0], # Returns is column 0\n",
    "                    'Cluster': train_clusters\n",
    "                })\n",
    "                \n",
    "                stats = temp_df.groupby('Cluster')['Ret'].mean().sort_values()\n",
    "                \n",
    "                # The cluster with lowest mean return = BEAR\n",
    "                # The cluster with highest mean return = BULL\n",
    "                # Middle = CHOP\n",
    "                if len(stats) == 3:\n",
    "                    bear_c = stats.index[0]\n",
    "                    chop_c = stats.index[1]\n",
    "                    bull_c = stats.index[2]\n",
    "                    \n",
    "                    mapping = {bear_c: 'BEAR', chop_c: 'CHOP', bull_c: 'BULL'}\n",
    "                else:\n",
    "                    # Fallback if GMM collapses to fewer clusters\n",
    "                    mapping = {c: 'CHOP' for c in stats.index}\n",
    "\n",
    "                # Apply mapping to the prediction window\n",
    "                regimes_mapped = [mapping.get(c, 'CHOP') for c in clusters_future]\n",
    "                \n",
    "                # Store results in the main DataFrame\n",
    "                # Use iloc for integer-based indexing on the slice\n",
    "                df.iloc[end_idx:predict_end_idx, df.columns.get_loc('Regime_Type')] = regimes_mapped\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Keep default 'CHOP' on failure\n",
    "                pass\n",
    "\n",
    "        # --- 3. Unshackled Signal Logic (unchanged from V9) ---\n",
    "        df['Signal'] = 0.0\n",
    "        \n",
    "        # A. BULL REGIME: \"Trust The Trend\"\n",
    "        bull_signal = (df['Regime_Type'] == 'BULL')\n",
    "        df.loc[bull_signal, 'Signal'] = 1.0\n",
    "        \n",
    "        # Boost: If Kalman agrees (Strong Trend), increase leverage\n",
    "        strong_trend = bull_signal & (df['Kalman_Slope'] > 0)\n",
    "        df.loc[strong_trend, 'Signal'] = 1.3\n",
    "        \n",
    "        # B. CHOP REGIME: \"Buy Dips\"\n",
    "        # chop_buy = (df['Regime_Type'] == 'CHOP') & (df['RSI'] < 45)\n",
    "        # df.loc[chop_buy, 'Signal'] = 1.0\n",
    "\n",
    "        # 1. Calculate a \"Floor\" (e.g., Lower Bollinger Band)\n",
    "        df['SMA_20'] = df['Adj Close'].rolling(20).mean()\n",
    "        df['BB_Lower'] = df['SMA_20'] - 2 * df['SMA_20'].rolling(20).std()\n",
    "\n",
    "        # 2. Strict Chop Entry\n",
    "        # OLD: RSI < 45\n",
    "        # NEW: RSI < 45 AND Price > BB_Lower (Don't buy if it's crashing through the floor)\n",
    "        #      AND FracDiff > -0.1 (Don't buy if trend is catastrophically negative)\n",
    "\n",
    "        chop_buy = (\n",
    "            (df['Regime_Type'] == 'CHOP') & \n",
    "            (df['RSI'] < 45) & \n",
    "            (df['Adj Close'] > df['BB_Lower']) # The Falling Knife Filter\n",
    "        )\n",
    "        df.loc[chop_buy, 'Signal'] = 1.0\n",
    "        \n",
    "        # C. BEAR REGIME: \"Survival\" (Cash unless deep panic)\n",
    "        panic_buy = (df['Regime_Type'] == 'BEAR') & (df['RSI'] < 25)\n",
    "        df.loc[panic_buy, 'Signal'] = 1.0\n",
    "        \n",
    "        # --- 4. The Alpha Clause (Macro Handling) ---\n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        \n",
    "        # Volatility Sizing (Risk Parity) [cite: 254]\n",
    "        vol_scaler = (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        \n",
    "        # Macro Filter: Halve size if SPY is bearish, but don't exit fully (Alpha Clause)\n",
    "        macro_scaler = df['Macro_Trend'].map({1: 1.0, 0: 0.5})\n",
    "        \n",
    "        df['Signal'] = df['Signal'] * vol_scaler * macro_scaler\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f7d61",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "80c0270b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy_Ensemble(BaseStrategy):\n",
    "    \"\"\"\n",
    "    The 'All-Weather' Ensemble.\n",
    "    \n",
    "    Combines V3 (Macro Trend) and V9 (Regime Unshackled) into a single\n",
    "    portfolio-level signal.\n",
    "    \n",
    "    Logic:\n",
    "    1. Runs V3 to capture high-beta trends (NVDA, Bitcoin).\n",
    "    2. Runs V9 to capture regime-based alpha and protect downside (JPM, BABA).\n",
    "    3. Blends signals using a 'Correlation-Adjusted' weighting or fixed 50/50.\n",
    "    4. Applies a final Volatility Target to the combined equity curve to ensure\n",
    "       the two strategies don't stack up to dangerous leverage.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date, w_v3=0.5, w_v9=0.5):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.w_v3 = w_v3\n",
    "        self.w_v9 = w_v9\n",
    "        # Instantiate sub-strategies\n",
    "        self.strat_v3 = StrategyV3_Macro(ticker, start_date, end_date)\n",
    "        self.strat_v9 = StrategyV9_RegimeUnshackled(ticker, start_date, end_date)\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        # Fetch once for efficiency (logic could be optimized to share DF, \n",
    "        # but separate fetch ensures cleaner encapsulation)\n",
    "        self.strat_v3.fetch_data(warmup_years)\n",
    "        self.strat_v9.fetch_data(warmup_years)\n",
    "        \n",
    "        # We share the index/data from one of them for the main wrapper\n",
    "        if self.strat_v3.data is not None and not self.strat_v3.data.empty:\n",
    "            self.data = self.strat_v3.data.copy()\n",
    "        elif self.strat_v9.data is not None:\n",
    "            self.data = self.strat_v9.data.copy()\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.strat_v3.data is None or self.strat_v9.data is None: return\n",
    "        \n",
    "        # 1. Generate Sub-Signals\n",
    "        self.strat_v3.generate_signals()\n",
    "        self.strat_v9.generate_signals()\n",
    "        \n",
    "        # Align Indices (Inner Join to be safe)\n",
    "        df = self.data.copy()\n",
    "        s3 = self.strat_v3.data['Signal']\n",
    "        s9 = self.strat_v9.data['Signal']\n",
    "        \n",
    "        # Merge signals into main DF\n",
    "        df['Sig_V3'] = s3\n",
    "        df['Sig_V9'] = s9\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # 2. The Allocation Logic\n",
    "        # Default: Fixed Weight (Core-Satellite Approach)\n",
    "        # V3 (Beta) + V9 (Alpha)\n",
    "        \n",
    "        # We blend the RAW signals.\n",
    "        # Note: Signals are already Vol-Targeted to ~15% inside sub-classes.\n",
    "        # Simple addition would double vol if correlation=1.\n",
    "        raw_blend = (df['Sig_V3'] * self.w_v3) + (df['Sig_V9'] * self.w_v9)\n",
    "        \n",
    "        # 3. Ensemble Volatility Control\n",
    "        # If V3 and V9 agree (both Long), we get high exposure.\n",
    "        # If they disagree (V3 Long, V9 Cash), we get half exposure.\n",
    "        # This naturally deleverages during uncertainty.\n",
    "        \n",
    "        df['Signal'] = raw_blend\n",
    "        \n",
    "        # Optional: Re-Target Volatility of the *Ensemble*\n",
    "        # (Prevents leverage creep if strategies are highly correlated)\n",
    "        # For now, we trust the weighted sum to act as a diversification benefit.\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b5a46",
   "metadata": {},
   "source": [
    "### Adaptive Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dd66f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy_Ensemble_Adaptive(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V10: The Adaptive Ensemble (Dynamic Weighting).\n",
    "    \n",
    "    Instead of fixed weights, this strategy re-allocates capital quarterly \n",
    "    based on the recent Risk-Adjusted Performance (Sharpe) of the sub-strategies.\n",
    "    \n",
    "    Logic:\n",
    "    1. Lookback: 126 Days (6 Months).\n",
    "    2. Rebalance: Every 63 Days (Quarterly).\n",
    "    3. Weighting:\n",
    "       - Calculate Sharpe Ratio for V3 and V9 in the lookback window.\n",
    "       - If Sharpe > 0: Weight is proportional to Sharpe.\n",
    "       - If Sharpe < 0: Weight is set to 0.\n",
    "       - Normalize weights to sum to 1.0.\n",
    "       \n",
    "    This allows the portfolio to automatically 'Risk On' into V3 during strong bulls\n",
    "    and 'Risk Off' into V9 during bears/chop.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        # Instantiate sub-strategies\n",
    "        self.strat_v3 = StrategyV3_Macro(ticker, start_date, end_date)\n",
    "        self.strat_v9 = StrategyV9_RegimeUnshackled(ticker, start_date, end_date)\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        self.strat_v3.fetch_data(warmup_years)\n",
    "        self.strat_v9.fetch_data(warmup_years)\n",
    "        \n",
    "        # Use one of the dataframes as the base\n",
    "        if self.strat_v3.data is not None and not self.strat_v3.data.empty:\n",
    "            self.data = self.strat_v3.data.copy()\n",
    "        elif self.strat_v9.data is not None:\n",
    "            self.data = self.strat_v9.data.copy()\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.strat_v3.data is None or self.strat_v9.data is None: return\n",
    "        \n",
    "        # 1. Generate Sub-Signals\n",
    "        self.strat_v3.generate_signals()\n",
    "        self.strat_v9.generate_signals()\n",
    "        \n",
    "        # Merge Data\n",
    "        df = self.data.copy()\n",
    "        df['Sig_V3'] = self.strat_v3.data['Signal']\n",
    "        df['Sig_V9'] = self.strat_v9.data['Signal']\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # 2. Simulate Sub-Strategy Returns (for metric calculation)\n",
    "        # We need to know how they *would* have performed to weight them.\n",
    "        # Lag signals by 1 to avoid lookahead bias when calculating returns.\n",
    "        df['Ret_V3'] = df['Sig_V3'].shift(1) * df['Returns']\n",
    "        df['Ret_V9'] = df['Sig_V9'].shift(1) * df['Returns']\n",
    "        \n",
    "        # 3. Walk-Forward Weight Optimization\n",
    "        df['W_V3'] = 0.5 # Default start\n",
    "        df['W_V9'] = 0.5\n",
    "        \n",
    "        lookback = 126      # 6 Months Lookback\n",
    "        rebalance_freq = 21 # Monthly Rebalance (Faster adaptation)\n",
    "        \n",
    "        indices = df.index\n",
    "        \n",
    "        if len(df) > lookback:\n",
    "            for t in range(lookback, len(df), rebalance_freq):\n",
    "                train_start = indices[t - lookback]\n",
    "                train_end = indices[t]\n",
    "                test_end_idx = min(t + rebalance_freq, len(df))\n",
    "                test_end = indices[test_end_idx - 1]\n",
    "                \n",
    "                # Calculate Sharpe in Lookback Window\n",
    "                # Add small epsilon to std to avoid division by zero\n",
    "                v3_mean = df.loc[train_start:train_end, 'Ret_V3'].mean()\n",
    "                v3_std = df.loc[train_start:train_end, 'Ret_V3'].std() + 1e-9\n",
    "                sharpe_v3 = (v3_mean / v3_std) * np.sqrt(252)\n",
    "                \n",
    "                v9_mean = df.loc[train_start:train_end, 'Ret_V9'].mean()\n",
    "                v9_std = df.loc[train_start:train_end, 'Ret_V9'].std() + 1e-9\n",
    "                sharpe_v9 = (v9_mean / v9_std) * np.sqrt(252)\n",
    "                \n",
    "                # Weighting Logic\n",
    "                # 1. Filter: If Sharpe is negative, set score to 0\n",
    "                score_v3 = max(0, sharpe_v3)\n",
    "                score_v9 = max(0, sharpe_v9)\n",
    "                \n",
    "                # 2. Normalize\n",
    "                total_score = score_v3 + score_v9\n",
    "                \n",
    "                if total_score > 0:\n",
    "                    w_v3 = score_v3 / total_score\n",
    "                    w_v9 = score_v9 / total_score\n",
    "                else:\n",
    "                    # Both are failing? Default to Defensive (V9) or Cash (0)\n",
    "                    # Let's default to V9 (Safety) as the 'bunker'\n",
    "                    w_v3 = 0.0\n",
    "                    w_v9 = 1.0\n",
    "                \n",
    "                # Apply weights to NEXT window\n",
    "                df.loc[train_end:test_end, 'W_V3'] = w_v3\n",
    "                df.loc[train_end:test_end, 'W_V9'] = w_v9\n",
    "                \n",
    "        # 4. Final Signal Generation\n",
    "        # Blend the signals using the dynamic weights\n",
    "        df['Signal'] = (df['Sig_V3'] * df['W_V3']) + (df['Sig_V9'] * df['W_V9'])\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ec1cd",
   "metadata": {},
   "source": [
    "### V12_Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5892e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV12_Macro_Switch(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V12: The Macro-Guided Ensemble.\n",
    "    \n",
    "    Replaces lookback windows with Real-Time Economic Data.\n",
    "    \n",
    "    DATA SOURCES (Yahoo Finance):\n",
    "    1. ^VIX: CBOE Volatility Index.\n",
    "    2. ^TNX: 10-Year Treasury Yield.\n",
    "    \n",
    "    LOGIC:\n",
    "    1. Calculate 'Macro Stress Score' (0.0 to 1.0).\n",
    "       - VIX Component: Normalized against recent history. High VIX = High Stress.\n",
    "       - Yield Component: Rate of Change (ROC) of TNX. Spiking rates = High Stress.\n",
    "    \n",
    "    2. Dynamic Weighting:\n",
    "       - Weight_V3 (Trend) = 1.0 - Stress_Score\n",
    "       - Weight_V9 (Safety) = Stress_Score\n",
    "       \n",
    "    HYPOTHESIS:\n",
    "    VIX and Rates often spike BEFORE the price crash is fully realized. \n",
    "    This allows the model to switch to safety faster than a Moving Average.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.v3 = StrategyV3_Macro(ticker, start_date, end_date)\n",
    "        self.v9 = StrategyV9_RegimeUnshackled(ticker, start_date, end_date)\n",
    "        # We store macro data separately\n",
    "        self.macro_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        # 1. Fetch Ticker Data\n",
    "        self.v3.fetch_data(warmup_years)\n",
    "        self.v9.fetch_data(warmup_years)\n",
    "        \n",
    "        if self.v3.data is None or self.v3.data.empty: return\n",
    "        self.data = self.v3.data.copy()\n",
    "        \n",
    "        # 2. Fetch Macro Data (VIX and TNX)\n",
    "        start_dt = (self.data.index[0] - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "        end_dt = self.end_date\n",
    "        \n",
    "        try:\n",
    "            vix = yf.download(\"^VIX\", start=start_dt, end=end_dt, progress=False, auto_adjust=True)\n",
    "            tnx = yf.download(\"^TNX\", start=start_dt, end=end_dt, progress=False, auto_adjust=True)\n",
    "            \n",
    "            # Cleaning\n",
    "            if isinstance(vix.columns, pd.MultiIndex): vix.columns = vix.columns.get_level_values(0)\n",
    "            if isinstance(tnx.columns, pd.MultiIndex): tnx.columns = tnx.columns.get_level_values(0)\n",
    "            \n",
    "            macro_df = pd.DataFrame(index=self.data.index)\n",
    "            # Align macro data to the ticker's trading days (ffill for holidays)\n",
    "            macro_df['VIX'] = vix['Close'].reindex(self.data.index, method='ffill')\n",
    "            macro_df['TNX'] = tnx['Close'].reindex(self.data.index, method='ffill')\n",
    "            \n",
    "            self.macro_data = macro_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Macro Data Fetch Error: {e}\")\n",
    "            # Fallback: Zero stress\n",
    "            self.macro_data = pd.DataFrame({'VIX': 20, 'TNX': 4}, index=self.data.index)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.macro_data is None: return\n",
    "        \n",
    "        # 1. Run Sub-Strategies\n",
    "        self.v3.generate_signals()\n",
    "        self.v9.generate_signals()\n",
    "        \n",
    "        # 2. Sync Data\n",
    "        df = self.data.copy()\n",
    "        df = df.join(self.v3.data[['Signal']].rename(columns={'Signal':'S_V3'}), how='left')\n",
    "        df = df.join(self.v9.data[['Signal']].rename(columns={'Signal':'S_V9'}), how='left')\n",
    "        \n",
    "        # 3. Calculate Macro Stress Score\n",
    "        macro = self.macro_data.copy()\n",
    "        \n",
    "        # A. VIX Stress (Fear)\n",
    "        # Normalize VIX: If VIX > 30, Stress = 1.0. If VIX < 15, Stress = 0.0.\n",
    "        # Uses a rolling Z-score or simple clamp? Simple clamp is more robust to regime shifts.\n",
    "        macro['VIX_Stress'] = ((macro['VIX'] - 15) / (30 - 15)).clip(0, 1)\n",
    "        \n",
    "        # B. Yield Stress (Rate Shock)\n",
    "        # We care about SPEED of rate rise, not just level.\n",
    "        # Calculate 20-day Rate of Change of TNX\n",
    "        macro['TNX_ROC'] = macro['TNX'].pct_change(20)\n",
    "        # If Yields rise > 10% in a month, that's a shock.\n",
    "        macro['TNX_Stress'] = (macro['TNX_ROC'] / 0.10).clip(0, 1)\n",
    "        \n",
    "        # Combined Stress (Max of either Fear or Rate Shock)\n",
    "        # We use Max because either one can crash the market independently.\n",
    "        macro['Total_Stress'] = macro[['VIX_Stress', 'TNX_Stress']].max(axis=1)\n",
    "        \n",
    "        # 4. Allocate Weights\n",
    "        # Smooth the stress signal to avoid daily jitter (3-day avg)\n",
    "        stress_signal = macro['Total_Stress'].rolling(3).mean().fillna(0)\n",
    "        \n",
    "        df['W_V9'] = stress_signal        # High Stress -> More Safety\n",
    "        df['W_V3'] = 1.0 - stress_signal  # Low Stress -> More Trend\n",
    "        \n",
    "        # 5. Final Signal\n",
    "        df['Signal'] = (df['S_V3'] * df['W_V3']) + (df['S_V9'] * df['W_V9'])\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec595138",
   "metadata": {},
   "source": [
    "### V21_MacroMom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "10ef132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV21_MacroMomentum(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V21: The Production Candidate.\n",
    "    \n",
    "    Architecture:\n",
    "    1. BASE: V20 Macro Stress Logic (VIX + TNX).\n",
    "    2. OVERRIDE: 'Trend Floor'. If the asset is structurally bullish \n",
    "       (Price > SMA200), we refuse to go to zero exposure, even if Macro is stressed.\n",
    "       \n",
    "    This solves the 'TSLA Problem' (missing rallies) without relying on \n",
    "    unstable Neural Networks.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.macro_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        super().fetch_data(warmup_years)\n",
    "        \n",
    "        # 1. Fetch Macro Data\n",
    "        try:\n",
    "            start_dt = self.data.index[0]\n",
    "            vix = yf.download(\"^VIX\", start=start_dt, end=self.end_date, progress=False, auto_adjust=True)\n",
    "            tnx = yf.download(\"^TNX\", start=start_dt, end=self.end_date, progress=False, auto_adjust=True)\n",
    "            \n",
    "            if isinstance(vix.columns, pd.MultiIndex): vix.columns = vix.columns.get_level_values(0)\n",
    "            if isinstance(tnx.columns, pd.MultiIndex): tnx.columns = tnx.columns.get_level_values(0)\n",
    "            \n",
    "            self.macro_data = pd.DataFrame(index=self.data.index)\n",
    "            self.macro_data['VIX'] = vix['Close'].reindex(self.data.index).fillna(method='ffill')\n",
    "            self.macro_data['TNX'] = tnx['Close'].reindex(self.data.index).fillna(method='ffill')\n",
    "        except:\n",
    "            self.macro_data = pd.DataFrame({'VIX': 20, 'TNX': 4.0}, index=self.data.index)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.macro_data is None: return\n",
    "        df = self.data.copy()\n",
    "        macro = self.macro_data.copy()\n",
    "        \n",
    "        # --- 1. Macro Stress Engine (V20 Logic) ---\n",
    "        # VIX Stress: Normalizing 12-35 range\n",
    "        macro['VIX_Stress'] = ((macro['VIX'] - 12) / 23).clip(0, 1)\n",
    "        \n",
    "        # Rates Stress: 1-Month Rate of Change > 10% is Panic\n",
    "        macro['TNX_ROC'] = macro['TNX'].pct_change(20)\n",
    "        macro['TNX_Stress'] = (macro['TNX_ROC'] / 0.10).clip(0, 1)\n",
    "        \n",
    "        # Combined Stress (Smoothed)\n",
    "        macro['Total_Stress'] = macro[['VIX_Stress', 'TNX_Stress']].max(axis=1).rolling(5).mean().fillna(0)\n",
    "        \n",
    "        # Base Signal: Inverse of Stress\n",
    "        df['Base_Signal'] = 1.0 - macro['Total_Stress']\n",
    "        \n",
    "        # --- 2. The Momentum Override (The Fix) ---\n",
    "        # \"Don't fight the tape.\"\n",
    "        \n",
    "        # Long Term Trend (SMA 200)\n",
    "        df['SMA_200'] = df['Adj Close'].rolling(200).mean()\n",
    "        df['Trend_Bull'] = (df['Adj Close'] > df['SMA_200'])\n",
    "        \n",
    "        # Momentum (RSI)\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df['Mom_Bull'] = (df['RSI'] > 50)\n",
    "        \n",
    "        # LOGIC: \n",
    "        # If Trend is BULL and Momentum is BULL, Minimum Signal = 0.5.\n",
    "        # This ensures we participate in \"Hated Rallies\" (like TSLA 2023)\n",
    "        # even if VIX is elevated.\n",
    "        \n",
    "        df['Signal'] = df['Base_Signal']\n",
    "        \n",
    "        # Apply Override\n",
    "        strong_uptrend = df['Trend_Bull'] & df['Mom_Bull']\n",
    "        df.loc[strong_uptrend, 'Signal'] = np.maximum(df.loc[strong_uptrend, 'Signal'], 0.5)\n",
    "        \n",
    "        # --- 3. Safety Veto (The \"Falling Knife\" Guard) ---\n",
    "        # If Price is crashing < Lower Bollinger, KILL the trade.\n",
    "        df['SMA_20'] = df['Adj Close'].rolling(20).mean()\n",
    "        df['BB_Lower'] = df['SMA_20'] - 2 * df['SMA_20'].rolling(20).std()\n",
    "        \n",
    "        # Allow tiny buffer (0.98)\n",
    "        is_crashing = df['Adj Close'] < (df['BB_Lower'] * 0.98)\n",
    "        df.loc[is_crashing, 'Signal'] = 0.0\n",
    "\n",
    "        # --- 4. Volatility Sizing ---\n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        vol_scaler = (target_vol / FeatureLab.yang_zhang_volatility(df)).clip(upper=1.5)\n",
    "        \n",
    "        df['Signal'] = df['Signal'] * vol_scaler\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b7fb6",
   "metadata": {},
   "source": [
    "### V21_MacroT_Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8640d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy_V21_Sector_Portfolio(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V21_Sector: Applies V21 Logic to the entire Sector Universe.\n",
    "    \n",
    "    This is the CONTROL strategy to fairly benchmark against TSR_V2.\n",
    "    It allows V21 to rotate into Energy/Defensives naturally if the \n",
    "    Macro/Trend logic dictates it.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        # Ticker is ignored, we load the Sector Basket\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.sectors = ['XLE', 'XLF', 'XLK', 'XLY', 'XLI', 'XLV', 'XLP', 'XLU', 'XLB']\n",
    "        self.sector_data = None\n",
    "        self.macro_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\") - timedelta(days=warmup_years*365)\n",
    "        start_str = start_dt.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        try:\n",
    "            # 1. Fetch Sector Data\n",
    "            sec_df = yf.download(self.sectors, start=start_str, end=self.end_date, progress=False, auto_adjust=True)\n",
    "            if isinstance(sec_df.columns, pd.MultiIndex):\n",
    "                self.sector_data = sec_df['Close'].fillna(method='ffill')\n",
    "            else:\n",
    "                self.sector_data = sec_df['Close'].fillna(method='ffill')\n",
    "\n",
    "            # 2. Fetch Macro Data (For V21 Logic)\n",
    "            macro_tickers = ['^VIX', '^TNX']\n",
    "            macro_df = yf.download(macro_tickers, start=start_str, end=self.end_date, progress=False, auto_adjust=True)\n",
    "            if isinstance(macro_df.columns, pd.MultiIndex):\n",
    "                self.macro_data = macro_df['Close'].fillna(method='ffill')\n",
    "            else:\n",
    "                self.macro_data = macro_df['Close'].fillna(method='ffill')\n",
    "                \n",
    "            # Base Container\n",
    "            self.data = pd.DataFrame(index=self.sector_data.index)\n",
    "            self.data['Adj Close'] = 100.0\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"V21 Sector Fetch Error: {e}\")\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.sector_data is None or self.macro_data is None: return\n",
    "        \n",
    "        # --- 1. Macro Stress Engine (V21 Global Logic) ---\n",
    "        macro = self.macro_data.copy()\n",
    "        macro['VIX_Stress'] = ((macro['^VIX'] - 12) / 23).clip(0, 1)\n",
    "        macro['TNX_ROC'] = macro['^TNX'].pct_change(20)\n",
    "        macro['TNX_Stress'] = (macro['TNX_ROC'] / 0.10).clip(0, 1)\n",
    "        macro['Total_Stress'] = macro[['VIX_Stress', 'TNX_Stress']].max(axis=1).rolling(5).mean().fillna(0)\n",
    "        \n",
    "        base_signal_strength = 1.0 - macro['Total_Stress']\n",
    "        \n",
    "        # --- 2. Sector-Level Logic Loop ---\n",
    "        # We calculate the V21 signal for EACH sector individually\n",
    "        active_weights = pd.DataFrame(0.0, index=self.sector_data.index, columns=self.sectors)\n",
    "        \n",
    "        for sector in self.sectors:\n",
    "            prices = self.sector_data[sector]\n",
    "            \n",
    "            # A. Trend Logic (SMA 200)\n",
    "            sma200 = prices.rolling(200).mean()\n",
    "            trend_bull = (prices > sma200)\n",
    "            \n",
    "            # B. Momentum Logic (RSI)\n",
    "            delta = prices.diff()\n",
    "            gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "            loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "            rs = gain / loss\n",
    "            rsi = 100 - (100 / (1 + rs))\n",
    "            mom_bull = (rsi > 50)\n",
    "            \n",
    "            # C. Falling Knife Logic (Bollinger Lower)\n",
    "            sma20 = prices.rolling(20).mean()\n",
    "            std20 = prices.rolling(20).std()\n",
    "            bb_lower = sma20 - 2 * std20\n",
    "            is_crashing = prices < (bb_lower * 0.98)\n",
    "            \n",
    "            # D. Combine\n",
    "            # Default = Base Signal (Macro Driven)\n",
    "            sig = base_signal_strength.copy()\n",
    "            \n",
    "            # Override: If Trend+Mom are Bullish, minimum exposure 0.5 (Ignore Macro Fear)\n",
    "            strong_uptrend = trend_bull & mom_bull\n",
    "            sig[strong_uptrend] = np.maximum(sig[strong_uptrend], 0.5)\n",
    "            \n",
    "            # Veto: If Crashing, Zero exposure\n",
    "            sig[is_crashing] = 0.0\n",
    "            \n",
    "            active_weights[sector] = sig\n",
    "\n",
    "        # --- 3. Portfolio Construction ---\n",
    "        # Equal Weight across all active signals\n",
    "        # If 5 sectors have signal 1.0, we hold 20% of each.\n",
    "        # If all 9 have signal 1.0, we hold 11% of each.\n",
    "        \n",
    "        # We normalize row-wise so leverage doesn't exceed 1.0? \n",
    "        # Or do we treat each as an independent bet?\n",
    "        # Let's Normalize to 1.0 leverage to be fair to TSR (which is usually L/S or 100% Long).\n",
    "        \n",
    "        total_signal = active_weights.sum(axis=1)\n",
    "        # Avoid division by zero\n",
    "        scale_factor = (1.0 / total_signal).replace([np.inf, -np.inf], 0.0).clip(0, 1)\n",
    "        \n",
    "        # Final Portfolio Weights\n",
    "        final_weights = active_weights.multiply(scale_factor, axis=0)\n",
    "        \n",
    "        # Calculate Returns\n",
    "        # Portfolio Return = Sum(Weight_i * Return_i)\n",
    "        sec_rets = self.sector_data.pct_change().fillna(0)\n",
    "        port_ret = (final_weights * sec_rets).sum(axis=1)\n",
    "        \n",
    "        self.data['Returns'] = port_ret\n",
    "        self.data['Net_Returns'] = port_ret\n",
    "        self.data['Signal'] = 1 # Dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6138504a",
   "metadata": {},
   "source": [
    "### Max Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2968a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy_CrystalBall(BaseStrategy):\n",
    "    \"\"\"\n",
    "    Theoretical Maximum: Perfect Foresight.\n",
    "    \n",
    "    Logic:\n",
    "    At the close of Day T, look at Day T+1 returns.\n",
    "    - If the best performing sector is > 0%: Buy 100% of that sector.\n",
    "    - If all sectors are negative: Hold Cash (0% return).\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.sectors = ['XLE', 'XLF', 'XLK', 'XLY', 'XLI', 'XLV', 'XLP', 'XLU', 'XLB']\n",
    "        self.sector_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=0):\n",
    "        # Fetch Sectors\n",
    "        try:\n",
    "            start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\") - timedelta(days=30) # Minimal warmup\n",
    "            sec_df = yf.download(self.sectors, start=start_dt.strftime(\"%Y-%m-%d\"), end=self.end_date, progress=False, auto_adjust=True)\n",
    "            \n",
    "            if isinstance(sec_df.columns, pd.MultiIndex):\n",
    "                self.sector_data = sec_df['Close'].fillna(method='ffill')\n",
    "            else:\n",
    "                self.sector_data = sec_df['Close'].fillna(method='ffill')\n",
    "                \n",
    "            self.data = pd.DataFrame(index=self.sector_data.index)\n",
    "            self.data['Adj Close'] = 100.0\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Crystal Ball Error: {e}\")\n",
    "\n",
    "    def generate_signals(self):\n",
    "        # Calculate Forward Returns (Lookahead Bias Intentional)\n",
    "        # Shift(-1) brings tomorrow's return to today.\n",
    "        rets = self.sector_data.pct_change().shift(-1).fillna(0)\n",
    "        \n",
    "        # Identify the Max Return for tomorrow\n",
    "        max_ret = rets.max(axis=1)\n",
    "        \n",
    "        # Strategy Return:\n",
    "        # If Max Ret > 0, we capture it.\n",
    "        # If Max Ret < 0, we stay in cash (0.0).\n",
    "        self.data['Net_Returns'] = np.where(max_ret > 0, max_ret, 0.0)\n",
    "\n",
    "    def run_backtest(self, transaction_cost=0.0, rebalance_threshold=0.0):\n",
    "        # Custom backtest for metrics\n",
    "        if self.data is None or self.data.empty: return\n",
    "        backtest_mask = self.data.index >= self.start_date\n",
    "        df = self.data.loc[backtest_mask].copy()\n",
    "        \n",
    "        df['Cumulative_Strategy'] = (1 + df['Net_Returns']).cumprod()\n",
    "        roll_max = df['Cumulative_Strategy'].cummax()\n",
    "        df['Drawdown'] = (df['Cumulative_Strategy'] / roll_max) - 1.0\n",
    "        self.results = df\n",
    "        \n",
    "        total_ret = df['Cumulative_Strategy'].iloc[-1] - 1\n",
    "        vol = df['Net_Returns'].std() * np.sqrt(252)\n",
    "        sharpe = (df['Net_Returns'].mean() / df['Net_Returns'].std()) * np.sqrt(252) if vol > 0 else 0\n",
    "        max_dd = df['Drawdown'].min()\n",
    "        \n",
    "        self.metrics = {'Total Return': total_ret, 'Sharpe Ratio': sharpe, 'Max Drawdown': max_dd}\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d534d0d",
   "metadata": {},
   "source": [
    "## New V4 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fb9865",
   "metadata": {},
   "source": [
    "### V22_SortioUnbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0ec7d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV22_Sortino_Unbound(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V22: The 'Sortino' Strategy (Fixes the NVDA/XLE Underperformance).\n",
    "    \n",
    "    CRITICAL IMPROVEMENT:\n",
    "    Standard volatility targeting (VolTarget / TotalVol) penalizes \"Good Volatility\" \n",
    "    (Upside breakouts). When NVDA goes parabolic, standard deviation explodes, \n",
    "    causing V3/V9 to cut position size.\n",
    "    \n",
    "    V22 replaces Total Volatility with 'Downside Deviation' for position sizing.\n",
    "    Logic:\n",
    "    1. Calculate Downside Deviation (volatility of negative returns only).\n",
    "    2. If price is skyrocketing (high total vol, low downside vol), we maintain FULL size.\n",
    "    3. If price is crashing (high downside vol), we cut size aggressivey.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        \n",
    "    def _calc_downside_deviation(self, returns, window=30):\n",
    "        # Filter for negative returns only, replace positive with 0\n",
    "        downside_rets = returns.copy()\n",
    "        downside_rets[downside_rets > 0] = 0\n",
    "        # Calculate rolling standard deviation of these negative returns\n",
    "        return downside_rets.rolling(window=window).std() * np.sqrt(252)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # 1. Base Features\n",
    "        df['FracDiff'] = FeatureLab.frac_diff_fixed(df['Adj Close'].apply(np.log), d=0.4, window=50)\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df['SMA_200'] = df['Adj Close'].rolling(200).mean()\n",
    "        \n",
    "        # 2. Base Signal (Trend Following)\n",
    "        # We want to be long if FracDiff is positive OR Price > SMA200 (Structural Bull)\n",
    "        df['Signal'] = 0.0\n",
    "        \n",
    "        bull_condition = (df['FracDiff'] > 0) | (df['Adj Close'] > df['SMA_200'])\n",
    "        df.loc[bull_condition, 'Signal'] = 1.0\n",
    "        \n",
    "        # 3. Sortino-Based Sizing (The Alpha Fix)\n",
    "        # Calculate Downside Volatility\n",
    "        df['Downside_Vol'] = self._calc_downside_deviation(df['Returns'])\n",
    "        \n",
    "        # Safety check for division by zero\n",
    "        df['Downside_Vol'].replace(0, 0.001, inplace=True)\n",
    "        \n",
    "        # Target Volatility (e.g., 10% downside risk, which is generous)\n",
    "        target_downside = 0.10 \n",
    "        \n",
    "        # Scalar = Target / Downside. \n",
    "        # If Downside Vol is 0 (Pure uptrend), Scalar explodes. We clip at 2.0 (2x leverage).\n",
    "        # This allows the strategy to ride NVDA up without cutting exposure.\n",
    "        df['Vol_Scaler'] = (target_downside / df['Downside_Vol']).clip(upper=2.0)\n",
    "        \n",
    "        # 4. Crisis Management (VIX Proxy or Price Action Veto)\n",
    "        # If RSI < 30 (Oversold) AND Downside Vol is spiking, we cut leverage\n",
    "        panic_mode = (df['RSI'] < 30) & (df['Downside_Vol'] > 0.20)\n",
    "        df.loc[panic_mode, 'Vol_Scaler'] = 0.5\n",
    "        \n",
    "        df['Signal'] = df['Signal'] * df['Vol_Scaler']\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba00b940",
   "metadata": {},
   "source": [
    "### V23_TurboTrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a288c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV23_TurboTrend(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V23: The 'Turbo Trend' Strategy.\n",
    "    \n",
    "    Designed specifically to capture 'Super-Trends' (NVDA, Crypto, XLE) where\n",
    "    volatility targeting (V3, V22) fails by reducing size too early.\n",
    "    \n",
    "    MECHANISM:\n",
    "    1. Entry: Structural Trend (Price > EMA_Short > EMA_Long).\n",
    "    2. Sizing: Fixed High Conviction (1.0 or 1.3). NO volatility dampening.\n",
    "    3. Exit: Chandelier Exit (ATR Trailing Stop).\n",
    "       - We trail the stop loss behind the highest high.\n",
    "       - If price hits the stop, we exit immediately.\n",
    "       \n",
    "    This ensures we stay 100% invested during the parabolic phase and only \n",
    "    exit when the structural trend actually breaks.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        \n",
    "    def _calculate_atr(self, df, window=14):\n",
    "        high_low = df['High'] - df['Low']\n",
    "        high_close = np.abs(df['High'] - df['Close'].shift())\n",
    "        low_close = np.abs(df['Low'] - df['Close'].shift())\n",
    "        ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "        true_range = ranges.max(axis=1)\n",
    "        return true_range.rolling(window).mean()\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # 1. Trend Features\n",
    "        df['EMA_20'] = df['Adj Close'].ewm(span=20, adjust=False).mean()\n",
    "        df['EMA_50'] = df['Adj Close'].ewm(span=50, adjust=False).mean()\n",
    "        df['EMA_200'] = df['Adj Close'].ewm(span=200, adjust=False).mean()\n",
    "        \n",
    "        # 2. ATR for Trailing Stop\n",
    "        df['ATR'] = self._calculate_atr(df, window=21)\n",
    "        \n",
    "        # 3. Chandelier Exit Calculation\n",
    "        # The \"Floor\" moves up, but never down, while in a trade.\n",
    "        # Here we simulate the logic vectorially.\n",
    "        \n",
    "        rolling_max = df['Adj Close'].rolling(window=22).max()\n",
    "        # A tighter multiplier (3.0) allows room for volatility but exits on crash\n",
    "        df['Trailing_Stop'] = rolling_max - (3.0 * df['ATR'])\n",
    "        \n",
    "        # 4. Signal Generation\n",
    "        df['Signal'] = 0.0\n",
    "        \n",
    "        # ENTRY CONDITION:\n",
    "        # A. Golden Alignment: Price > EMA20 > EMA50\n",
    "        # B. Structural Bull: Price > EMA200 (Filter out dead cat bounces in bear markets)\n",
    "        entry_cond = (df['Adj Close'] > df['EMA_20']) & \\\n",
    "                     (df['EMA_20'] > df['EMA_50']) & \\\n",
    "                     (df['Adj Close'] > df['EMA_200'])\n",
    "        \n",
    "        # EXIT CONDITION:\n",
    "        # Price closes below Trailing Stop\n",
    "        exit_cond = (df['Adj Close'] < df['Trailing_Stop'])\n",
    "        \n",
    "        # Vectorized Position Management\n",
    "        # We start with 0. If Entry -> 1. If Exit -> 0.\n",
    "        # We need to forward-fill the \"In Trade\" state.\n",
    "        \n",
    "        # Create a state mask\n",
    "        signals = np.zeros(len(df))\n",
    "        in_trade = False\n",
    "        \n",
    "        # Iterating for state management (cleanest way for trailing stops)\n",
    "        price = df['Adj Close'].values\n",
    "        ema_20 = df['EMA_20'].values\n",
    "        ema_50 = df['EMA_50'].values\n",
    "        ema_200 = df['EMA_200'].values\n",
    "        stops = df['Trailing_Stop'].values\n",
    "        \n",
    "        for i in range(1, len(df)):\n",
    "            # Update State\n",
    "            if in_trade:\n",
    "                # Check Exit\n",
    "                if price[i] < stops[i]:\n",
    "                    signals[i] = 0\n",
    "                    in_trade = False\n",
    "                else:\n",
    "                    signals[i] = 1 # Hold\n",
    "            else:\n",
    "                # Check Entry\n",
    "                if (price[i] > ema_20[i]) and (ema_20[i] > ema_50[i]) and (price[i] > ema_200[i]):\n",
    "                    signals[i] = 1\n",
    "                    in_trade = True\n",
    "                else:\n",
    "                    signals[i] = 0\n",
    "                    \n",
    "        df['Signal'] = signals\n",
    "        \n",
    "        # 5. NO Volatility Targeting\n",
    "        # We apply a fixed leverage for strong trends if desired, or just 1.0.\n",
    "        # Let's set to 1.0 (Full Invested). \n",
    "        # Note: If you want leverage on NVDA, change this to 1.3\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00862249",
   "metadata": {},
   "source": [
    "### V24_Accelerating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "df1024c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV24_Accelerator(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V24: The 'Accelerator' Strategy.\n",
    "    \n",
    "    Evolution of V23 (Turbo). Designed for Tech Momentum (NVDA/TSLA).\n",
    "    \n",
    "    KEY FEATURES:\n",
    "    1. Structural Entry: Price > EMA20 > EMA50 > EMA200.\n",
    "    2. Accelerator Exit: A Dynamic Chandelier Exit.\n",
    "       - Base Stop: 3.5x ATR (Loose, allows initial volatility).\n",
    "       - Level 1: If Profit > 15%, tighten to 2.5x ATR.\n",
    "       - Level 2: If Profit > 30%, tighten to 1.5x ATR.\n",
    "       \n",
    "    This solves the \"TSLA Problem\" where massive gains evaporate \n",
    "    because the trailing stop was too loose at the top.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        \n",
    "    def _calculate_atr(self, df, window=14):\n",
    "        high_low = df['High'] - df['Low']\n",
    "        high_close = np.abs(df['High'] - df['Close'].shift())\n",
    "        low_close = np.abs(df['Low'] - df['Close'].shift())\n",
    "        ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "        true_range = ranges.max(axis=1)\n",
    "        return true_range.rolling(window).mean()\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # 1. Technicals\n",
    "        df['EMA_20'] = df['Adj Close'].ewm(span=20, adjust=False).mean()\n",
    "        df['EMA_50'] = df['Adj Close'].ewm(span=50, adjust=False).mean()\n",
    "        df['EMA_200'] = df['Adj Close'].ewm(span=200, adjust=False).mean()\n",
    "        df['ATR'] = self._calculate_atr(df, window=14)\n",
    "        \n",
    "        # 2. Vectorized Backtest Loop (Required for Dynamic Stops)\n",
    "        # We cannot do this purely vectorially because 'Profit' depends on 'Entry Price'\n",
    "        \n",
    "        signals = np.zeros(len(df))\n",
    "        price = df['Adj Close'].values\n",
    "        high = df['High'].values\n",
    "        ema_20 = df['EMA_20'].values\n",
    "        ema_50 = df['EMA_50'].values\n",
    "        ema_200 = df['EMA_200'].values\n",
    "        atr = df['ATR'].values\n",
    "        \n",
    "        in_trade = False\n",
    "        entry_price = 0.0\n",
    "        highest_high_since_entry = 0.0\n",
    "        \n",
    "        for i in range(1, len(df)):\n",
    "            if np.isnan(atr[i]): continue\n",
    "            \n",
    "            if in_trade:\n",
    "                # A. Update Highest High\n",
    "                if high[i] > highest_high_since_entry:\n",
    "                    highest_high_since_entry = high[i]\n",
    "                \n",
    "                # B. Calculate Dynamic Multiplier based on Unrealized ROI (Peak)\n",
    "                roi = (highest_high_since_entry - entry_price) / entry_price\n",
    "                \n",
    "                if roi > 0.30:\n",
    "                    mult = 1.5 # Lock it in tight!\n",
    "                elif roi > 0.15:\n",
    "                    mult = 2.5 # Tighten up\n",
    "                else:\n",
    "                    mult = 3.5 # Give it room\n",
    "                \n",
    "                # C. Calculate Stop Price\n",
    "                stop_price = highest_high_since_entry - (mult * atr[i])\n",
    "                \n",
    "                # D. Check Exit\n",
    "                if price[i] < stop_price:\n",
    "                    signals[i] = 0\n",
    "                    in_trade = False\n",
    "                else:\n",
    "                    signals[i] = 1 # Stay Long\n",
    "            \n",
    "            else:\n",
    "                # Check Entry: Strict Golden Alignment\n",
    "                is_bull_trend = (price[i] > ema_20[i]) and \\\n",
    "                                (ema_20[i] > ema_50[i]) and \\\n",
    "                                (ema_50[i] > ema_200[i])\n",
    "                \n",
    "                if is_bull_trend:\n",
    "                    signals[i] = 1\n",
    "                    in_trade = True\n",
    "                    entry_price = price[i]\n",
    "                    highest_high_since_entry = high[i]\n",
    "                else:\n",
    "                    signals[i] = 0\n",
    "        \n",
    "        df['Signal'] = signals\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2ce674",
   "metadata": {},
   "source": [
    "### V25_Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6189293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV25_PrecisionTrend(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V25: The 'Precision Trend' Strategy.\n",
    "    \n",
    "    Replaces EMA Crossovers (laggy) with RSI Regime logic (fast).\n",
    "    Designed to function as the \"Bull Leg\" of Agent V4.\n",
    "    \n",
    "    MECHANISM:\n",
    "    1. Filter: Structural Bull (Price > SMA200).\n",
    "    2. Entry: Momentum Ignition (RSI crosses above 50).\n",
    "    3. Exit: Chandelier Exit (Highest High - 3.0 * ATR).\n",
    "    \n",
    "    Why this beats V24:\n",
    "    - RSI > 50 gets us into JPM/NVDA moves weeks earlier than EMA20 > EMA50.\n",
    "    - Standard Chandelier Stop prevents the \"suffocation\" seen in TSLA V24.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        \n",
    "    def _calculate_atr(self, df, window=14):\n",
    "        high_low = df['High'] - df['Low']\n",
    "        high_close = np.abs(df['High'] - df['Close'].shift())\n",
    "        low_close = np.abs(df['Low'] - df['Close'].shift())\n",
    "        ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "        true_range = ranges.max(axis=1)\n",
    "        return true_range.rolling(window).mean()\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # 1. Features\n",
    "        df['SMA_200'] = df['Adj Close'].rolling(200).mean()\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'], window=14)\n",
    "        df['ATR'] = self._calculate_atr(df, window=14)\n",
    "        \n",
    "        # 2. Chandelier Exit (Vectorized Simulation)\n",
    "        # We simulate the trailing stop logic.\n",
    "        \n",
    "        signals = np.zeros(len(df))\n",
    "        price = df['Adj Close'].values\n",
    "        high = df['High'].values\n",
    "        sma_200 = df['SMA_200'].values\n",
    "        rsi = df['RSI'].values\n",
    "        atr = df['ATR'].values\n",
    "        \n",
    "        in_trade = False\n",
    "        highest_high = 0.0\n",
    "        \n",
    "        for i in range(1, len(df)):\n",
    "            if np.isnan(sma_200[i]) or np.isnan(atr[i]): continue\n",
    "            \n",
    "            if in_trade:\n",
    "                # Update Trailing Stop\n",
    "                if high[i] > highest_high:\n",
    "                    highest_high = high[i]\n",
    "                \n",
    "                # Standard Chandelier: 3.0 ATR\n",
    "                stop_price = highest_high - (3.0 * atr[i])\n",
    "                \n",
    "                # Exit Trigger\n",
    "                if price[i] < stop_price:\n",
    "                    signals[i] = 0\n",
    "                    in_trade = False\n",
    "                else:\n",
    "                    signals[i] = 1\n",
    "            else:\n",
    "                # Entry Trigger\n",
    "                # 1. Structural Bull (Price > SMA200)\n",
    "                # 2. Momentum Active (RSI > 50) - \"The Bull Zone\"\n",
    "                if (price[i] > sma_200[i]) and (rsi[i] > 50):\n",
    "                    signals[i] = 1\n",
    "                    in_trade = True\n",
    "                    highest_high = high[i]\n",
    "                else:\n",
    "                    signals[i] = 0\n",
    "                    \n",
    "        df['Signal'] = signals\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e54b9",
   "metadata": {},
   "source": [
    "### Agent V1: Auto Regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6ace5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRegimeAgent(BaseStrategy):\n",
    "    \"\"\"\n",
    "    The 'Meta-Controller' Agent.\n",
    "    \n",
    "    Instead of blending strategies (Ensemble), this Agent acts as a Switch.\n",
    "    It identifies the market 'Context' and deploys the single best specialist \n",
    "    model for that context.\n",
    "    \n",
    "    STATES:\n",
    "    1. TRENDING (ADX > 25): Deploy V22_Sortino (Ride the wave).\n",
    "    2. MEAN REVERSION (ADX < 20): Deploy V9_Unshackled (Trade the chop).\n",
    "    3. STRESS (VIX > 25 or TNX Spiking): Deploy Cash/Safety.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        # Initialize the specialists\n",
    "        self.trend_model = StrategyV22_Sortino_Unbound(ticker, start_date, end_date)\n",
    "        self.chop_model = StrategyV9_RegimeUnshackled(ticker, start_date, end_date)\n",
    "        self.macro_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        # Fetch underlying data once\n",
    "        self.trend_model.fetch_data(warmup_years)\n",
    "        self.chop_model.fetch_data(warmup_years)\n",
    "        \n",
    "        if self.trend_model.data is not None:\n",
    "            self.data = self.trend_model.data.copy()\n",
    "            \n",
    "        # Fetch Context Data (VIX)\n",
    "        try:\n",
    "            vix = yf.download(\"^VIX\", start=self.data.index[0], end=self.end_date, progress=False, auto_adjust=True)\n",
    "            if isinstance(vix.columns, pd.MultiIndex): vix.columns = vix.columns.get_level_values(0)\n",
    "            self.macro_data = vix['Close'].reindex(self.data.index).fillna(method='ffill')\n",
    "        except:\n",
    "            self.macro_data = pd.Series(20, index=self.data.index)\n",
    "\n",
    "    def _calculate_adx(self, df, window=14):\n",
    "        \"\"\"Calculate Trend Strength (ADX)\"\"\"\n",
    "        high = df['High']\n",
    "        low = df['Low']\n",
    "        close = df['Close']\n",
    "        \n",
    "        plus_dm = high.diff()\n",
    "        minus_dm = low.diff()\n",
    "        plus_dm[plus_dm < 0] = 0\n",
    "        minus_dm[minus_dm > 0] = 0\n",
    "        \n",
    "        tr1 = pd.DataFrame(high - low)\n",
    "        tr2 = pd.DataFrame(abs(high - close.shift(1)))\n",
    "        tr3 = pd.DataFrame(abs(low - close.shift(1)))\n",
    "        frames = [tr1, tr2, tr3]\n",
    "        tr = pd.concat(frames, axis=1, join='outer').max(axis=1)\n",
    "        atr = tr.rolling(window).mean()\n",
    "        \n",
    "        plus_di = 100 * (plus_dm.ewm(alpha=1/window).mean() / atr)\n",
    "        minus_di = 100 * (abs(minus_dm).ewm(alpha=1/window).mean() / atr)\n",
    "        dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n",
    "        adx = dx.rolling(window).mean()\n",
    "        return adx.fillna(20)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None: return\n",
    "        \n",
    "        # 1. Generate Specialist Signals\n",
    "        self.trend_model.generate_signals()\n",
    "        self.chop_model.generate_signals()\n",
    "        \n",
    "        # 2. Align Data\n",
    "        df = self.data.copy()\n",
    "        df['Sig_Trend'] = self.trend_model.data['Signal']\n",
    "        df['Sig_Chop'] = self.chop_model.data['Signal']\n",
    "        df['VIX'] = self.macro_data\n",
    "        \n",
    "        # 3. Calculate Context (ADX)\n",
    "        df['ADX'] = self._calculate_adx(df)\n",
    "        \n",
    "        # 4. Agent Logic (The Switchboard)\n",
    "        df['Active_Model'] = 'CASH'\n",
    "        df['Signal'] = 0.0\n",
    "        \n",
    "        # Logic Loop\n",
    "        # If VIX is high, we don't trust the Trend model (too much risk), \n",
    "        # but we might trust V9 (which has Bear/Panic logic).\n",
    "        \n",
    "        # Vectorized implementation for speed\n",
    "        # Condition A: Strong Trend -> Use V22\n",
    "        cond_trend = (df['ADX'] > 25) & (df['VIX'] < 30)\n",
    "        \n",
    "        # Condition B: Chop/Noise -> Use V9\n",
    "        cond_chop = (df['ADX'] <= 25) & (df['VIX'] < 35)\n",
    "        \n",
    "        # Condition C: Extreme Stress -> Cash (Implicit in Signal=0 default)\n",
    "        \n",
    "        # Apply Logic\n",
    "        # We prefer Trend if both are true (Trend is usually more profitable)\n",
    "        df.loc[cond_chop, 'Signal'] = df.loc[cond_chop, 'Sig_Chop']\n",
    "        df.loc[cond_trend, 'Signal'] = df.loc[cond_trend, 'Sig_Trend']\n",
    "        \n",
    "        # Final Volatility Safety Overlay (Agent Level)\n",
    "        # Even if V22 says \"Go\", if VIX > 40, the Agent vetoes.\n",
    "        df.loc[df['VIX'] > 40, 'Signal'] = 0.0\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b1541c",
   "metadata": {},
   "source": [
    "### Agent V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fef5f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "# NOTE: Assumes BaseStrategy, StrategyV9_RegimeUnshackled, and StrategyV23_TurboTrend are available\n",
    "\n",
    "class AutoRegimeAgent_V2(BaseStrategy):\n",
    "    \"\"\"\n",
    "    Agent V2: Macro-Aware & Turbo-Enabled.\n",
    "    \n",
    "    Improves upon the original Agent by:\n",
    "    1. Using V23 (TurboTrend) for Growth phases (Solving NVDA/XLE).\n",
    "    2. Incorporating Macro Data (VIX/TNX) to handle Cyclicals (Solving JPM).\n",
    "    3. Retaining V9 (Unshackled) for Chop/Correction phases (Solving TSLA/BABA).\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        # Specialist 1: The Trend Hunter\n",
    "        self.trend_model = StrategyV23_TurboTrend(ticker, start_date, end_date)\n",
    "        # Specialist 2: The Chop Survivor\n",
    "        self.chop_model = StrategyV9_RegimeUnshackled(ticker, start_date, end_date)\n",
    "        \n",
    "        self.macro_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        # 1. Fetch Specialist Data\n",
    "        self.trend_model.fetch_data(warmup_years)\n",
    "        self.chop_model.fetch_data(warmup_years)\n",
    "        \n",
    "        if self.trend_model.data is not None:\n",
    "            self.data = self.trend_model.data.copy()\n",
    "            \n",
    "        # 2. Fetch Macro Context (VIX and TNX)\n",
    "        try:\n",
    "            start_dt = self.data.index[0]\n",
    "            macro_tickers = [\"^VIX\", \"^TNX\"]\n",
    "            macro_df = yf.download(macro_tickers, start=start_dt, end=self.end_date, progress=False, auto_adjust=True)\n",
    "            \n",
    "            # Handle MultiIndex\n",
    "            if isinstance(macro_df.columns, pd.MultiIndex):\n",
    "                self.macro_data = macro_df['Close'].fillna(method='ffill')\n",
    "            else:\n",
    "                self.macro_data = macro_df['Close'].fillna(method='ffill')\n",
    "                \n",
    "            # Align to asset index\n",
    "            self.macro_data = self.macro_data.reindex(self.data.index).fillna(method='ffill')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Agent Macro Fetch Error: {e}\")\n",
    "            # Fallback\n",
    "            self.macro_data = pd.DataFrame({'^VIX': 20, '^TNX': 4.0}, index=self.data.index)\n",
    "\n",
    "    def _calculate_adx(self, df, window=14):\n",
    "        # Standard ADX calculation\n",
    "        high = df['High']\n",
    "        low = df['Low']\n",
    "        close = df['Close']\n",
    "        \n",
    "        plus_dm = high.diff()\n",
    "        minus_dm = low.diff()\n",
    "        plus_dm[plus_dm < 0] = 0\n",
    "        minus_dm[minus_dm > 0] = 0\n",
    "        \n",
    "        tr1 = pd.DataFrame(high - low)\n",
    "        tr2 = pd.DataFrame(abs(high - close.shift(1)))\n",
    "        tr3 = pd.DataFrame(abs(low - close.shift(1)))\n",
    "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "        atr = tr.rolling(window).mean()\n",
    "        \n",
    "        plus_di = 100 * (plus_dm.ewm(alpha=1/window).mean() / atr)\n",
    "        minus_di = 100 * (abs(minus_dm).ewm(alpha=1/window).mean() / atr)\n",
    "        dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n",
    "        adx = dx.rolling(window).mean().fillna(20)\n",
    "        return adx\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.macro_data is None: return\n",
    "        \n",
    "        # 1. Run Specialists\n",
    "        self.trend_model.generate_signals()\n",
    "        self.chop_model.generate_signals()\n",
    "        \n",
    "        # 2. Build Decision Matrix\n",
    "        df = self.data.copy()\n",
    "        df['Sig_Turbo'] = self.trend_model.data['Signal']\n",
    "        df['Sig_Chop'] = self.chop_model.data['Signal']\n",
    "        \n",
    "        # Context Features\n",
    "        df['ADX'] = self._calculate_adx(df)\n",
    "        df['VIX'] = self.macro_data['^VIX']\n",
    "        \n",
    "        # TNX Rate of Change (for Macro Stress)\n",
    "        df['TNX_ROC'] = self.macro_data['^TNX'].pct_change(20)\n",
    "        \n",
    "        # 3. Agent State Logic\n",
    "        df['Signal'] = 0.0\n",
    "        \n",
    "        # Thresholds\n",
    "        VIX_PANIC = 30.0\n",
    "        TNX_SHOCK = 0.15 # 15% rise in yields in a month\n",
    "        ADX_TREND = 25.0\n",
    "        \n",
    "        # State A: MACRO STRESS (The \"JPM/Real Estate\" Logic)\n",
    "        # If yields are spiking or fear is extreme, we default to safety (Cash or V9 Defensive).\n",
    "        # However, if ADX is EXTREME (>50), we might ignore Macro (Idiosyncratic Breakout like Crypto).\n",
    "        is_macro_stress = (df['VIX'] > VIX_PANIC) | (df['TNX_ROC'] > TNX_SHOCK)\n",
    "        \n",
    "        # State B: TURBO TREND (The \"NVDA\" Logic)\n",
    "        # Strong ADX and Price Structure.\n",
    "        is_turbo_trend = (df['ADX'] > ADX_TREND)\n",
    "        \n",
    "        # LOGIC TREE\n",
    "        # Default: Use Chop Model (V9) - Good for accumulation and mean reversion\n",
    "        df['Signal'] = df['Sig_Chop']\n",
    "        \n",
    "        # Override 1: If Turbo Trend -> Switch to V23\n",
    "        # We allow V23 to override Macro Stress IF the trend is extremely strong (ADX > 40)\n",
    "        # This solves XLE/NVDA rallying despite market fear.\n",
    "        strong_override = (df['ADX'] > 40)\n",
    "        \n",
    "        use_turbo = (is_turbo_trend & ~is_macro_stress) | strong_override\n",
    "        df.loc[use_turbo, 'Signal'] = df.loc[use_turbo, 'Sig_Turbo']\n",
    "        \n",
    "        # Override 2: If Macro Stress (and no override) -> Safety\n",
    "        # In this case, we can either go to 0.0 (Cash) or use V9's defensive logic.\n",
    "        # V9 already has logic for Bears, but let's be safer.\n",
    "        force_cash = is_macro_stress & ~strong_override\n",
    "        df.loc[force_cash, 'Signal'] = 0.0\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9abcb69",
   "metadata": {},
   "source": [
    "### Agent V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fd97f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRegimeAgent_V3(BaseStrategy):\n",
    "    \"\"\"\n",
    "    Agent V3: The 'Smart' Tech Agent.\n",
    "    \n",
    "    Fixes the 'Blind ADX' bug from V2.\n",
    "    \n",
    "    LOGIC:\n",
    "    1. Panic Filter: If VIX > 32, Cash. (Ignores TNX to save Banks).\n",
    "    2. Trend Filter: \n",
    "       - If ADX > 25 AND PDI > MDI (Bull Trend) -> V24 Accelerator.\n",
    "       - If ADX > 25 AND PDI < MDI (Bear Trend) -> V9 Unshackled (Mean Rev).\n",
    "    3. Chop Filter:\n",
    "       - If ADX < 25 -> V9 Unshackled.\n",
    "       \n",
    "    This ensures we don't apply Turbo strategies to crashing stocks (BABA),\n",
    "    restoring the defensive Alpha.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        # Specialist 1: The Accelerator (Bull Trend)\n",
    "        self.trend_model = StrategyV24_Accelerator(ticker, start_date, end_date)\n",
    "        # Specialist 2: The Unshackled (Bear/Chop)\n",
    "        self.chop_model = StrategyV9_RegimeUnshackled(ticker, start_date, end_date)\n",
    "        \n",
    "        self.macro_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        self.trend_model.fetch_data(warmup_years)\n",
    "        self.chop_model.fetch_data(warmup_years)\n",
    "        \n",
    "        if self.trend_model.data is not None:\n",
    "            self.data = self.trend_model.data.copy()\n",
    "            \n",
    "        try:\n",
    "            # Only fetch VIX for this version\n",
    "            vix = yf.download(\"^VIX\", start=self.data.index[0], end=self.end_date, progress=False, auto_adjust=True)\n",
    "            if isinstance(vix.columns, pd.MultiIndex): vix.columns = vix.columns.get_level_values(0)\n",
    "            self.macro_data = vix['Close'].reindex(self.data.index).fillna(method='ffill')\n",
    "        except:\n",
    "            self.macro_data = pd.Series(20, index=self.data.index)\n",
    "\n",
    "    def _calculate_dmi(self, df, window=14):\n",
    "        \"\"\"Calculates ADX, Plus_DI, and Minus_DI\"\"\"\n",
    "        high = df['High']\n",
    "        low = df['Low']\n",
    "        close = df['Close']\n",
    "        \n",
    "        plus_dm = high.diff()\n",
    "        minus_dm = low.diff()\n",
    "        plus_dm[plus_dm < 0] = 0\n",
    "        minus_dm[minus_dm > 0] = 0\n",
    "        \n",
    "        tr1 = pd.DataFrame(high - low)\n",
    "        tr2 = pd.DataFrame(abs(high - close.shift(1)))\n",
    "        tr3 = pd.DataFrame(abs(low - close.shift(1)))\n",
    "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "        atr = tr.rolling(window).mean()\n",
    "        \n",
    "        # Calculate DI+ and DI-\n",
    "        plus_di = 100 * (plus_dm.ewm(alpha=1/window).mean() / atr)\n",
    "        minus_di = 100 * (abs(minus_dm).ewm(alpha=1/window).mean() / atr)\n",
    "        \n",
    "        dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n",
    "        adx = dx.rolling(window).mean().fillna(20)\n",
    "        \n",
    "        return adx, plus_di, minus_di\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.macro_data is None: return\n",
    "        \n",
    "        # 1. Run Specialists\n",
    "        self.trend_model.generate_signals()\n",
    "        self.chop_model.generate_signals()\n",
    "        \n",
    "        # 2. Build Decision Context\n",
    "        df = self.data.copy()\n",
    "        df['Sig_Turbo'] = self.trend_model.data['Signal']\n",
    "        df['Sig_Chop'] = self.chop_model.data['Signal']\n",
    "        df['VIX'] = self.macro_data\n",
    "        \n",
    "        # Calculate Directional Indicators\n",
    "        df['ADX'], df['PDI'], df['MDI'] = self._calculate_dmi(df)\n",
    "        \n",
    "        # 3. Agent Logic\n",
    "        df['Signal'] = 0.0\n",
    "        \n",
    "        # A. PANIC (Global Circuit Breaker)\n",
    "        is_panic = (df['VIX'] > 32)\n",
    "        \n",
    "        # B. BULL TREND (Strong ADX + Bulls in Control)\n",
    "        # Note: We rely on PDI > MDI to confirm direction\n",
    "        is_bull_trend = (df['ADX'] > 25) & (df['PDI'] > df['MDI'])\n",
    "        \n",
    "        # C. Logic Application\n",
    "        \n",
    "        # Default: Use Chop Model (Handles Chop AND Bear Trends via Mean Rev)\n",
    "        # This covers BABA (Bear) and TSLA (Chop phases)\n",
    "        df['Signal'] = df['Sig_Chop']\n",
    "        \n",
    "        # Override: Use Turbo Model ONLY if Bull Trend AND Not Panic\n",
    "        # This covers NVDA/JPM Rallies\n",
    "        use_turbo = (is_bull_trend & ~is_panic)\n",
    "        df.loc[use_turbo, 'Signal'] = df.loc[use_turbo, 'Sig_Turbo']\n",
    "        \n",
    "        # Override: Force Cash if Panic (Optional, V9 handles this partly, but let's be safe)\n",
    "        df.loc[is_panic, 'Signal'] = 0.0\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f32ae",
   "metadata": {},
   "source": [
    "### Agent V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b3f5cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRegimeAgent_V4(BaseStrategy):\n",
    "    \"\"\"\n",
    "    Agent V4: The 'Guardrail' Agent.\n",
    "    \n",
    "    The definitive solution for the Tech/Cyclical split.\n",
    "    \n",
    "    CORE LOGIC:\n",
    "    The SMA200 is the \"Great Divider\".\n",
    "    - Below SMA200 (Bear Market): Trend Following FAILS (Whipsaw). We MUST use Mean Reversion (V9).\n",
    "    - Above SMA200 (Bull Market): Mean Reversion UNDERPERFORMS. We MUST use Trend Following (V25).\n",
    "    \n",
    "    This simple rule solves the BABA/TSLA crash performance while preserving NVDA upside.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        # The Bull Specialist\n",
    "        self.bull_model = StrategyV25_PrecisionTrend(ticker, start_date, end_date)\n",
    "        # The Bear Specialist\n",
    "        self.bear_model = StrategyV9_RegimeUnshackled(ticker, start_date, end_date)\n",
    "        \n",
    "        self.macro_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        self.bull_model.fetch_data(warmup_years)\n",
    "        self.bear_model.fetch_data(warmup_years)\n",
    "        \n",
    "        if self.bull_model.data is not None:\n",
    "            self.data = self.bull_model.data.copy()\n",
    "            \n",
    "        try:\n",
    "            vix = yf.download(\"^VIX\", start=self.data.index[0], end=self.end_date, progress=False, auto_adjust=True)\n",
    "            if isinstance(vix.columns, pd.MultiIndex): vix.columns = vix.columns.get_level_values(0)\n",
    "            self.macro_data = vix['Close'].reindex(self.data.index).fillna(method='ffill')\n",
    "        except:\n",
    "            self.macro_data = pd.Series(20, index=self.data.index)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.macro_data is None: return\n",
    "        \n",
    "        # 1. Run Specialists\n",
    "        self.bull_model.generate_signals()\n",
    "        self.bear_model.generate_signals()\n",
    "        \n",
    "        # 2. Context\n",
    "        df = self.data.copy()\n",
    "        df['Sig_Bull'] = self.bull_model.data['Signal']\n",
    "        df['Sig_Bear'] = self.bear_model.data['Signal']\n",
    "        df['VIX'] = self.macro_data\n",
    "        \n",
    "        # 3. Structural Filter (The Guardrail)\n",
    "        df['SMA_200'] = df['Adj Close'].rolling(200).mean()\n",
    "        \n",
    "        # 4. Logic Tree\n",
    "        df['Signal'] = 0.0\n",
    "        \n",
    "        # Condition A: Structural Bear (Price < SMA200) OR Panic (VIX > 32)\n",
    "        # In this zone, we ONLY trust the Unshackled V9 model (which buys deep dips and shorts rips)\n",
    "        is_defensive_zone = (df['Adj Close'] < df['SMA_200']) | (df['VIX'] > 32)\n",
    "        \n",
    "        # Condition B: Structural Bull (Price > SMA200) AND Calm (VIX < 32)\n",
    "        # In this zone, we trust the Precision Trend V25 model\n",
    "        is_aggressive_zone = ~is_defensive_zone\n",
    "        \n",
    "        # Apply Signals\n",
    "        # Note: Vectorized assignment\n",
    "        df.loc[is_defensive_zone, 'Signal'] = df.loc[is_defensive_zone, 'Sig_Bear']\n",
    "        df.loc[is_aggressive_zone, 'Signal'] = df.loc[is_aggressive_zone, 'Sig_Bull']\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb0296",
   "metadata": {},
   "source": [
    "### Agent V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "af04db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRegimeAgent_V5(BaseStrategy):\n",
    "    \"\"\"\n",
    "    Agent V5: The Composite Agent.\n",
    "    \n",
    "    Combines the best-performing components from previous iterations:\n",
    "    1. BULL ENGINE: V23_TurboTrend (From Agent V2) - Best for NVDA/TSLA.\n",
    "    2. BEAR ENGINE: V9_Unshackled (From Agent V1) - Best for BABA/Chop.\n",
    "    3. LOGIC: V4 Guardrails + V12 Macro Awareness.\n",
    "    \n",
    "    HIERARCHY:\n",
    "    1. Structural Bear (Price < SMA200) -> Force V9.\n",
    "    2. Macro Stress (High VIX/Rates)   -> Force V9.\n",
    "    3. Bull Trend (ADX > 20)           -> Force V23.\n",
    "    4. Chop (Low ADX)                  -> Force V9.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        # Specialist 1: Turbo Trend (Restored)\n",
    "        self.bull_model = StrategyV23_TurboTrend(ticker, start_date, end_date)\n",
    "        # Specialist 2: Unshackled Regime\n",
    "        self.bear_model = StrategyV9_RegimeUnshackled(ticker, start_date, end_date)\n",
    "        \n",
    "        self.macro_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        self.bull_model.fetch_data(warmup_years)\n",
    "        self.bear_model.fetch_data(warmup_years)\n",
    "        \n",
    "        if self.bull_model.data is not None:\n",
    "            self.data = self.bull_model.data.copy()\n",
    "            \n",
    "        try:\n",
    "            # Fetch Macro Data (V12 Logic)\n",
    "            tickers = [\"^VIX\", \"^TNX\"]\n",
    "            macro_df = yf.download(tickers, start=self.data.index[0], end=self.end_date, progress=False, auto_adjust=True)\n",
    "            if isinstance(macro_df.columns, pd.MultiIndex): \n",
    "                # Flatten\n",
    "                self.macro_data = pd.DataFrame({\n",
    "                    'VIX': macro_df['Close']['^VIX'],\n",
    "                    'TNX': macro_df['Close']['^TNX']\n",
    "                })\n",
    "            else:\n",
    "                 self.macro_data = pd.DataFrame({\n",
    "                    'VIX': macro_df['Close']['^VIX'],\n",
    "                    'TNX': macro_df['Close']['^TNX']\n",
    "                })\n",
    "            \n",
    "            # Reindex to match asset\n",
    "            self.macro_data = self.macro_data.reindex(self.data.index).fillna(method='ffill')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Agent V5 Macro Fetch Error: {e}\")\n",
    "            self.macro_data = pd.DataFrame({'VIX': 20, 'TNX': 4.0}, index=self.data.index)\n",
    "\n",
    "    def _calculate_adx(self, df, window=14):\n",
    "        high = df['High']\n",
    "        low = df['Low']\n",
    "        close = df['Close']\n",
    "        \n",
    "        plus_dm = high.diff()\n",
    "        minus_dm = low.diff()\n",
    "        plus_dm[plus_dm < 0] = 0\n",
    "        minus_dm[minus_dm > 0] = 0\n",
    "        \n",
    "        tr1 = pd.DataFrame(high - low)\n",
    "        tr2 = pd.DataFrame(abs(high - close.shift(1)))\n",
    "        tr3 = pd.DataFrame(abs(low - close.shift(1)))\n",
    "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "        atr = tr.rolling(window).mean()\n",
    "        \n",
    "        plus_di = 100 * (plus_dm.ewm(alpha=1/window).mean() / atr)\n",
    "        minus_di = 100 * (abs(minus_dm).ewm(alpha=1/window).mean() / atr)\n",
    "        dx = (abs(plus_di - minus_di) / abs(plus_di + minus_di)) * 100\n",
    "        adx = dx.rolling(window).mean().fillna(20)\n",
    "        return adx\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.macro_data is None: return\n",
    "        \n",
    "        # 1. Run Specialists\n",
    "        self.bull_model.generate_signals()\n",
    "        self.bear_model.generate_signals()\n",
    "        \n",
    "        # 2. Construct Context\n",
    "        df = self.data.copy()\n",
    "        df['Sig_Bull'] = self.bull_model.data['Signal']\n",
    "        df['Sig_Bear'] = self.bear_model.data['Signal']\n",
    "        \n",
    "        # Features\n",
    "        df['SMA_200'] = df['Adj Close'].rolling(200).mean()\n",
    "        df['ADX'] = self._calculate_adx(df)\n",
    "        \n",
    "        # Macro Stress (V12 Logic)\n",
    "        macro = self.macro_data.copy()\n",
    "        macro['TNX_ROC'] = macro['TNX'].pct_change(20)\n",
    "        \n",
    "        # Stress Conditions\n",
    "        # VIX > 30 is Panic\n",
    "        # TNX Rising > 15% in a month is Rate Shock (Bad for JPM/Tech)\n",
    "        df['Macro_Panic'] = (macro['VIX'] > 30) | (macro['TNX_ROC'] > 0.15)\n",
    "        \n",
    "        # 3. Agent Logic Hierarchy\n",
    "        df['Signal'] = 0.0\n",
    "        \n",
    "        # Check 1: Structural Bear Market (Iron Floor)\n",
    "        # If Price < SMA200, we DO NOT TRUST TREND MODELS. We use V9.\n",
    "        is_structural_bear = df['Adj Close'] < df['SMA_200']\n",
    "        \n",
    "        # Check 2: Macro Panic\n",
    "        # If VIX/Rates are spiking, we go Defensive (V9)\n",
    "        is_panic = df['Macro_Panic']\n",
    "        \n",
    "        # Check 3: Bull Trend\n",
    "        # If NOT Bear AND NOT Panic AND ADX > 20\n",
    "        is_bull_trend = (~is_structural_bear) & (~is_panic) & (df['ADX'] > 20)\n",
    "        \n",
    "        # Default: V9 (Chop/Defensive)\n",
    "        df['Signal'] = df['Sig_Bear']\n",
    "        \n",
    "        # Override: V23 (Turbo)\n",
    "        # Only if conditions are perfect\n",
    "        df.loc[is_bull_trend, 'Signal'] = df.loc[is_bull_trend, 'Sig_Bull']\n",
    "        \n",
    "        # Note: If is_structural_bear or is_panic is True, we stay with the Default (V9).\n",
    "        # This fixes BABA (Bear) and JPM (Panic).\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9089a187",
   "metadata": {},
   "source": [
    "### Agent V6: Darwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2e321c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRegimeAgent_V6_Darwin(BaseStrategy):\n",
    "    \"\"\"\n",
    "    Agent V6: The 'Darwinian' Adaptive Agent.\n",
    "    \n",
    "    Instead of hardcoded logic rules (IF/ELSE), this Agent uses \n",
    "    Walk-Forward Optimization (Online Learning) to select the best model.\n",
    "    \n",
    "    MECHANISM:\n",
    "    1. Runs V9, V12, and V23 in the background (Virtual Accounts).\n",
    "    2. Calculates a Rolling Sharpe Ratio (63-day lookback) for each.\n",
    "    3. Allocates 100% capital to the strategy with the highest Realized Sharpe.\n",
    "    4. \"Cash Veto\": If the best strategy has Negative Sharpe, go to Cash.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        # The Candidates\n",
    "        self.strat_v9 = StrategyV9_RegimeUnshackled(ticker, start_date, end_date)\n",
    "        self.strat_v12 = StrategyV12_Macro_Switch(ticker, start_date, end_date)\n",
    "        self.strat_v23 = StrategyV23_TurboTrend(ticker, start_date, end_date)\n",
    "        \n",
    "        # Parameters\n",
    "        self.lookback_window = 63  # 3 Months for Regime Detection\n",
    "        \n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        # Fetch data for all candidates\n",
    "        self.strat_v9.fetch_data(warmup_years)\n",
    "        self.strat_v12.fetch_data(warmup_years)\n",
    "        self.strat_v23.fetch_data(warmup_years)\n",
    "        \n",
    "        # Use V23 data as the base (it likely has the cleanest index)\n",
    "        if self.strat_v23.data is not None:\n",
    "            self.data = self.strat_v23.data.copy()\n",
    "            \n",
    "    def generate_signals(self):\n",
    "        # Check if sub-strategies have data\n",
    "        if self.strat_v9.data is None or self.strat_v12.data is None or self.strat_v23.data is None:\n",
    "            return\n",
    "\n",
    "        # 1. Generate Sub-Strategy Signals\n",
    "        self.strat_v9.generate_signals()\n",
    "        self.strat_v12.generate_signals()\n",
    "        self.strat_v23.generate_signals()\n",
    "        \n",
    "        # 2. Prepare Virtual Account DataFrame\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # Align signals to the main index (Left Join)\n",
    "        s9 = self.strat_v9.data['Signal'].reindex(df.index).fillna(0)\n",
    "        s12 = self.strat_v12.data['Signal'].reindex(df.index).fillna(0)\n",
    "        s23 = self.strat_v23.data['Signal'].reindex(df.index).fillna(0)\n",
    "        \n",
    "        # Calculate Daily Returns of the Asset\n",
    "        # (Assuming 'Returns' column exists, if not calculate it)\n",
    "        if 'Returns' not in df.columns:\n",
    "            df['Returns'] = df['Adj Close'].pct_change()\n",
    "            \n",
    "        market_ret = df['Returns'].fillna(0)\n",
    "        \n",
    "        # 3. Calculate Virtual Strategy Returns (Realized Performance)\n",
    "        # Shift signal by 1 because Signal T acts on Return T+1\n",
    "        # (Or Signal T is generated at Close T, acts on Close T+1)\n",
    "        # Standard Backtest convention: Ret_Strat = Signal.shift(1) * Returns\n",
    "        \n",
    "        ret_v9 = s9.shift(1) * market_ret\n",
    "        ret_v12 = s12.shift(1) * market_ret\n",
    "        ret_v23 = s23.shift(1) * market_ret\n",
    "        \n",
    "        # 4. Walk-Forward Selection Loop (Vectorized Rolling)\n",
    "        \n",
    "        # Calculate Rolling Mean and Std for Sharpe Ratio\n",
    "        # Epsilon to avoid div by zero\n",
    "        eps = 1e-9\n",
    "        \n",
    "        # V9 Metrics\n",
    "        roll_mean_9 = ret_v9.rolling(self.lookback_window).mean()\n",
    "        roll_std_9 = ret_v9.rolling(self.lookback_window).std() + eps\n",
    "        sharpe_9 = (roll_mean_9 / roll_std_9) * np.sqrt(252)\n",
    "        \n",
    "        # V12 Metrics\n",
    "        roll_mean_12 = ret_v12.rolling(self.lookback_window).mean()\n",
    "        roll_std_12 = ret_v12.rolling(self.lookback_window).std() + eps\n",
    "        sharpe_12 = (roll_mean_12 / roll_std_12) * np.sqrt(252)\n",
    "        \n",
    "        # V23 Metrics\n",
    "        roll_mean_23 = ret_v23.rolling(self.lookback_window).mean()\n",
    "        roll_std_23 = ret_v23.rolling(self.lookback_window).std() + eps\n",
    "        sharpe_23 = (roll_mean_23 / roll_std_23) * np.sqrt(252)\n",
    "        \n",
    "        # 5. Selection Logic\n",
    "        \n",
    "        # Stack scores into a DataFrame for easy comparison\n",
    "        scores = pd.DataFrame({\n",
    "            'V9': sharpe_9,\n",
    "            'V12': sharpe_12,\n",
    "            'V23': sharpe_23\n",
    "        })\n",
    "        \n",
    "        # Identify Winner (Column name with max value)\n",
    "        # idxmax returns the column name of the max value\n",
    "        winners = scores.idxmax(axis=1)\n",
    "        best_scores = scores.max(axis=1)\n",
    "        \n",
    "        # 6. Construct Final Signal\n",
    "        # We must decide TODAY'S signal based on YESTERDAY'S winner to avoid lookahead.\n",
    "        # However, the Rolling calculation already includes today's return in the window end.\n",
    "        # To be strictly safe: We use the Winner determined at T-1 to choose the Signal from T.\n",
    "        \n",
    "        # Shift the decision by 1 day\n",
    "        active_strategy = winners.shift(1)\n",
    "        active_score = best_scores.shift(1)\n",
    "        \n",
    "        final_signal = np.zeros(len(df))\n",
    "        \n",
    "        # Map strategy names to their signal arrays\n",
    "        sig_map = {\n",
    "            'V9': s9.values,\n",
    "            'V12': s12.values,\n",
    "            'V23': s23.values\n",
    "        }\n",
    "        \n",
    "        strat_names = active_strategy.values\n",
    "        scores_vals = active_score.values\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            strat = strat_names[i]\n",
    "            score = scores_vals[i]\n",
    "            \n",
    "            # Cash Veto: If the best strategy is losing money (Sharpe < 0), go to Cash.\n",
    "            if score < 0 or pd.isna(score):\n",
    "                final_signal[i] = 0.0\n",
    "            elif isinstance(strat, str) and strat in sig_map:\n",
    "                final_signal[i] = sig_map[strat][i]\n",
    "            else:\n",
    "                final_signal[i] = 0.0\n",
    "                \n",
    "        df['Signal'] = final_signal\n",
    "        \n",
    "        # Store for debugging/visualization\n",
    "        df['Active_Strat'] = active_strategy\n",
    "        df['Active_Score'] = active_score\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f6ae43",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c02190db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustBenchmark:\n",
    "    \"\"\"\n",
    "    Implements Walk-Forward Analysis and Deflated Sharpe Ratio logic.\n",
    "    Benchmarks multiple strategies without look-ahead bias[cite: 275].\n",
    "    \"\"\"\n",
    "    def __init__(self, tickers, start_date, end_date):\n",
    "        self.tickers = tickers\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.results = []\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"{'STRATEGY':<10} | {'TICKER':<6} | {'ANN RET':<7} | {'SHARPE':<6} | {'MAX DD':<7} | {'NOTES'}\")\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        strategies = {\n",
    "            \"V1_Base\": StrategyV1_Baseline,\n",
    "        }\n",
    "\n",
    "        for ticker in self.tickers:\n",
    "            # Capture Buy & Hold first\n",
    "            bh = StrategyV1_Baseline(ticker, self.start_date, self.end_date)\n",
    "            bh.fetch_data()\n",
    "            bh.data['Signal'] = 1 # Force Buy\n",
    "            bh.run_backtest()\n",
    "            self._print_row(\"Buy&Hold\", ticker, bh.metrics)\n",
    "            \n",
    "            for name, StratClass in strategies.items():\n",
    "                try:\n",
    "                    strat = StratClass(ticker, self.start_date, self.end_date)\n",
    "                    strat.fetch_data(warmup_years=2)\n",
    "                    strat.generate_signals()\n",
    "                    strat.run_backtest()\n",
    "                    \n",
    "                    self._print_row(name, ticker, strat.metrics)\n",
    "                    \n",
    "                    # Store for portfolio level (optional)\n",
    "                    self.results.append({\n",
    "                        'Ticker': ticker,\n",
    "                        'Strategy': name,\n",
    "                        'Returns': strat.results['Net_Returns']\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed {name} {ticker}: {e}\")\n",
    "            print(\"-\" * 75)\n",
    "\n",
    "    def _print_row(self, name, ticker, metrics):\n",
    "        if not metrics: return\n",
    "        ret = metrics['Total Return']\n",
    "        # Annualize return approx\n",
    "        ann_ret = (1 + ret) ** (252 / len(metrics.get('Returns', [1]*252))) - 1 if 'Returns' in metrics else ret\n",
    "        print(f\"{name:<10} | {ticker:<6} | {ret:.1%}   | {metrics['Sharpe Ratio']:.2f}   | {metrics['Max Drawdown']:.1%}   |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e37a7620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRATEGY     | TICKER | ANN RET | SHARPE | MAX DD  | NOTES\n",
      "-------------------------------------------------------------------------------\n",
      "Buy&Hold   | NVDA   | 355.4%   | 1.19   | -62.7%   |\n",
      "V9_Unshackled | NVDA   | 61.9%   | 0.88   | -16.7%   |\n",
      "V12_Macro  | NVDA   | 159.6%   | 1.57   | -16.7%   |\n",
      "AgentV1    | NVDA   | 141.6%   | 1.51   | -17.2%   |\n",
      "AgentV2    | NVDA   | 319.9%   | 1.67   | -17.3%   |\n",
      "AgentV3    | NVDA   | 261.7%   | 1.56   | -16.3%   |\n",
      "AgentV4    | NVDA   | 220.9%   | 1.19   | -29.2%   |\n",
      "AgentV6    | NVDA   | 114.7%   | 1.18   | -19.6%   |\n",
      "-------------------------------------------------------------------------------\n",
      "Buy&Hold   | JPM    | 62.1%   | 0.77   | -37.9%   |\n",
      "V9_Unshackled | JPM    | 39.2%   | 0.70   | -16.7%   |\n",
      "V12_Macro  | JPM    | 93.1%   | 1.25   | -13.7%   |\n",
      "AgentV1    | JPM    | 71.8%   | 1.02   | -14.8%   |\n",
      "AgentV2    | JPM    | 45.2%   | 0.82   | -14.7%   |\n",
      "AgentV3    | JPM    | 16.7%   | 0.39   | -16.4%   |\n",
      "AgentV4    | JPM    | 5.8%   | 0.21   | -20.2%   |\n",
      "AgentV6    | JPM    | 66.4%   | 1.06   | -19.5%   |\n",
      "-------------------------------------------------------------------------------\n",
      "Buy&Hold   | TSLA   | 7.9%   | 0.35   | -73.0%   |\n",
      "V9_Unshackled | TSLA   | 49.6%   | 0.86   | -18.7%   |\n",
      "V12_Macro  | TSLA   | 30.8%   | 0.58   | -25.0%   |\n",
      "AgentV1    | TSLA   | 68.7%   | 0.98   | -19.7%   |\n",
      "AgentV2    | TSLA   | 86.0%   | 0.89   | -30.0%   |\n",
      "AgentV3    | TSLA   | 5.7%   | 0.20   | -42.3%   |\n",
      "AgentV4    | TSLA   | 11.0%   | 0.28   | -47.8%   |\n",
      "AgentV6    | TSLA   | 39.8%   | 0.59   | -28.7%   |\n",
      "-------------------------------------------------------------------------------\n",
      "Buy&Hold   | BABA   | -26.9%   | 0.06   | -54.0%   |\n",
      "V9_Unshackled | BABA   | 1.8%   | 0.11   | -18.5%   |\n",
      "V12_Macro  | BABA   | 0.4%   | 0.08   | -22.0%   |\n",
      "AgentV1    | BABA   | 25.0%   | 0.51   | -13.0%   |\n",
      "AgentV2    | BABA   | -23.7%   | -0.47   | -30.7%   |\n",
      "AgentV3    | BABA   | -16.6%   | -0.41   | -24.3%   |\n",
      "AgentV4    | BABA   | 12.6%   | 0.29   | -29.0%   |\n",
      "AgentV6    | BABA   | 1.1%   | 0.10   | -24.9%   |\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'STRATEGY':<12} | {'TICKER':<6} | {'ANN RET':<7} | {'SHARPE':<6} | {'MAX DD':<7} | {'NOTES'}\")\n",
    "print(\"-\" * 79)\n",
    "\n",
    "class Strategy_Ensemble_Growth(Strategy_Ensemble):\n",
    "    def __init__(self, ticker, start, end): super().__init__(ticker, start, end, 0.7, 0.3)\n",
    "\n",
    "strategies = {\n",
    "    # \"V3_Macro\": StrategyV3_Macro,\n",
    "    \"V9_Unshackled\": StrategyV9_RegimeUnshackled,\n",
    "    \"V12_Macro\": StrategyV12_Macro_Switch,\n",
    "    # \"V21_MacroMom\": StrategyV21_MacroMomentum,\n",
    "    # \"Ens_Growth\": Strategy_Ensemble_Growth,\n",
    "    # \"V23_Turbo\": StrategyV23_TurboTrend,\n",
    "    # \"V25_Prec\": StrategyV25_PrecisionTrend,\n",
    "    \"AgentV1\": AutoRegimeAgent,\n",
    "    \"AgentV2\": AutoRegimeAgent_V2,\n",
    "    \"AgentV3\": AutoRegimeAgent_V3,\n",
    "    \"AgentV4\": AutoRegimeAgent_V4,\n",
    "    \"AgentV6\": AutoRegimeAgent_V6_Darwin,\n",
    "}\n",
    "\n",
    "# Same Stress Test Basket\n",
    "tickers = [\"NVDA\", \"JPM\", \"TSLA\", \"BABA\"]\n",
    "\n",
    "bench = RobustBenchmark(\n",
    "    tickers=tickers, \n",
    "    start_date=\"2022-01-01\", \n",
    "    end_date=\"2024-12-30\"\n",
    ")\n",
    "\n",
    "# Manual run loop to handle the specific classes\n",
    "for ticker in tickers:\n",
    "    # Buy & Hold\n",
    "    bh = StrategyV1_Baseline(ticker, bench.start_date, bench.end_date)\n",
    "    bh.fetch_data()\n",
    "    bh.data['Signal'] = 1\n",
    "    bh.run_backtest()\n",
    "    bench._print_row(\"Buy&Hold\", ticker, bh.metrics)\n",
    "    \n",
    "    for name, StratClass in strategies.items():\n",
    "        try:\n",
    "            strat = StratClass(ticker, bench.start_date, bench.end_date)\n",
    "            strat.fetch_data(warmup_years=2)\n",
    "            strat.generate_signals()\n",
    "            strat.run_backtest()\n",
    "            bench._print_row(name, ticker, strat.metrics)\n",
    "        except Exception as e:\n",
    "            print(f\"Err {name} {ticker}: {e}\")\n",
    "    print(\"-\" * 79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6e86aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{'STRATEGY':<15} | {'DESC':<12} | {'ANN RET':<7} | {'SHARPE':<6} | {'MAX DD':<7}\")\n",
    "# print(\"-\" * 65)\n",
    "\n",
    "# bench_final = RobustBenchmark(tickers=[\"SHOWDOWN\"], start_date=\"2022-01-01\", end_date=\"2024-12-30\")\n",
    "\n",
    "# # 1. The Ceiling (Crystal Ball)\n",
    "# max_pot = Strategy_CrystalBall(\"CRYSTAL\", bench_final.start_date, bench_final.end_date)\n",
    "# max_pot.fetch_data()\n",
    "# max_pot.generate_signals()\n",
    "# max_pot.run_backtest()\n",
    "# bench_final._print_row(\"Crystal_Ball\", \"Max Potential\", max_pot.metrics)\n",
    "\n",
    "# # 2. V21 (Base Trend)\n",
    "# v21 = Strategy_V21_Sector_Portfolio(\"BASKET\", bench_final.start_date, bench_final.end_date)\n",
    "# v21.fetch_data()\n",
    "# v21.generate_signals()\n",
    "# v21.run_backtest()\n",
    "# bench_final._print_row(\"V21_Base\", \"Trend Only\", v21.metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
