{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4be3e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from abc import ABC, abstractmethod\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db667cc",
   "metadata": {},
   "source": [
    "## 1. FEATURE ENGINEERING LAB (The Math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14adbb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLab:\n",
    "    \"\"\"Shared mathematical engine for technical and statistical features.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_weights_frac_diff(d, size, threshold=1e-5):\n",
    "        w = [1.0]\n",
    "        for k in range(1, size):\n",
    "            w_k = -w[-1] / k * (d - k + 1)\n",
    "            w.append(w_k)\n",
    "        w = np.array(w[::-1])\n",
    "        w = w[np.abs(w) > threshold]\n",
    "        return w\n",
    "\n",
    "    @staticmethod\n",
    "    def frac_diff_fixed(series, d, window=50):\n",
    "        # Solves Stationarity Dilemma [cite: 61]\n",
    "        weights = FeatureLab.get_weights_frac_diff(d, window)\n",
    "        res = series.rolling(window=len(weights)).apply(lambda x: np.dot(x, weights), raw=True)\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def yang_zhang_volatility(df, window=30):\n",
    "        # Captures intraday energy/gaps [cite: 82]\n",
    "        log_ho = (df['High'] / df['Open']).apply(np.log)\n",
    "        log_lo = (df['Low'] / df['Open']).apply(np.log)\n",
    "        log_co = (df['Close'] / df['Open']).apply(np.log)\n",
    "        log_oc = (df['Open'] / df['Close'].shift(1)).apply(np.log)\n",
    "        log_cc = (df['Close'] / df['Close'].shift(1)).apply(np.log)\n",
    "        \n",
    "        rs = log_ho * (log_ho - log_co) + log_lo * (log_lo - log_co)\n",
    "        close_vol = log_cc.rolling(window=window).var()\n",
    "        open_vol = log_oc.rolling(window=window).var()\n",
    "        window_rs = rs.rolling(window=window).mean()\n",
    "\n",
    "        k = 0.34 / (1.34 + (window + 1) / (window - 1))\n",
    "        return np.sqrt(open_vol + k * window_rs)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_rsi(series, window=14):\n",
    "        delta = series.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rs = gain / loss\n",
    "        return 100 - (100 / (1 + rs))\n",
    "\n",
    "    @staticmethod\n",
    "    def triple_barrier_labels(prices, vol, pt=1.0, sl=1.0, barrier_window=10):\n",
    "        \"\"\"\n",
    "        Implements the Triple Barrier Method.\n",
    "        Labels: 1 (Profit Target Hit), -1 (Stop Loss Hit), 0 (Time Limit/Neutral)\n",
    "        \"\"\"\n",
    "        labels = pd.Series(0, index=prices.index)\n",
    "        # Shift prices to align future outcome with current row\n",
    "        # However, to avoid look-ahead in features, we usually compute label for row t based on t+1...t+k\n",
    "        # This function generates the TARGET variable (y) for training.\n",
    "        \n",
    "        limit = len(prices) - barrier_window\n",
    "        p_values = prices.values\n",
    "        v_values = vol.values\n",
    "        \n",
    "        for i in range(limit):\n",
    "            current_p = p_values[i]\n",
    "            current_vol = v_values[i]\n",
    "            \n",
    "            # Dynamic barriers based on volatility [cite: 215]\n",
    "            target = current_p * (1 + pt * current_vol)\n",
    "            stop = current_p * (1 - sl * current_vol)\n",
    "            \n",
    "            future_window = p_values[i+1 : i+1+barrier_window]\n",
    "            \n",
    "            hit_target = np.where(future_window >= target)[0]\n",
    "            hit_stop = np.where(future_window <= stop)[0]\n",
    "            \n",
    "            first_target = hit_target[0] if len(hit_target) > 0 else barrier_window + 1\n",
    "            first_stop = hit_stop[0] if len(hit_stop) > 0 else barrier_window + 1\n",
    "            \n",
    "            if first_target < first_stop and first_target <= barrier_window:\n",
    "                labels.iloc[i] = 1\n",
    "            elif first_stop < first_target and first_stop <= barrier_window:\n",
    "                labels.iloc[i] = 0 # In Meta-Labeling, we often treat Stop (-1) as 0 (Do Not Trade)\n",
    "            # Else 0 (Time limit reached or neutral)\n",
    "            \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40668a35",
   "metadata": {},
   "source": [
    "## 2. BASE STRATEGY INFRASTRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5398e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStrategy(ABC):\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        self.ticker = ticker\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.data = None\n",
    "        self.results = None\n",
    "        self.metrics = {}\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\")\n",
    "        warmup_start_dt = start_dt - timedelta(days=warmup_years*365)\n",
    "        warmup_start_str = warmup_start_dt.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        try:\n",
    "            self.data = yf.download(self.ticker, start=warmup_start_str, end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(self.data.columns, pd.MultiIndex): \n",
    "                self.data.columns = self.data.columns.get_level_values(0)\n",
    "            if 'Adj Close' not in self.data.columns: \n",
    "                self.data['Adj Close'] = self.data['Close']\n",
    "            self.data['Returns'] = self.data['Adj Close'].pct_change()\n",
    "            self.data.dropna(inplace=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {self.ticker}: {e}\")\n",
    "            self.data = pd.DataFrame()\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_signals(self):\n",
    "        pass\n",
    "\n",
    "    def run_backtest(self, transaction_cost=0.0005, rebalance_threshold=0.1):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        \n",
    "        backtest_mask = self.data.index >= self.start_date\n",
    "        df = self.data.loc[backtest_mask].copy()\n",
    "        if df.empty: return\n",
    "\n",
    "        # Position Smoothing\n",
    "        clean_positions = []\n",
    "        current_pos = 0.0\n",
    "        raw_signals = df['Signal'].values\n",
    "        \n",
    "        for target in raw_signals:\n",
    "            if abs(target - current_pos) > rebalance_threshold:\n",
    "                current_pos = target\n",
    "            clean_positions.append(current_pos)\n",
    "            \n",
    "        df['Position'] = clean_positions\n",
    "        df['Prev_Position'] = df['Position'].shift(1).fillna(0)\n",
    "        df['Turnover'] = (df['Prev_Position'] - df['Position'].shift(2).fillna(0)).abs()\n",
    "        df['Gross_Returns'] = df['Prev_Position'] * df['Returns']\n",
    "        df['Net_Returns'] = df['Gross_Returns'] - (df['Turnover'] * transaction_cost)\n",
    "        df['Net_Returns'].fillna(0, inplace=True)\n",
    "        \n",
    "        df['Cumulative_Strategy'] = (1 + df['Net_Returns']).cumprod()\n",
    "        df['Cumulative_Market'] = (1 + df['Returns']).cumprod()\n",
    "        \n",
    "        roll_max = df['Cumulative_Strategy'].cummax()\n",
    "        df['Drawdown'] = (df['Cumulative_Strategy'] / roll_max) - 1.0\n",
    "        \n",
    "        self.results = df\n",
    "        \n",
    "        # Performance Calculation\n",
    "        total_ret = df['Cumulative_Strategy'].iloc[-1] - 1\n",
    "        vol = df['Net_Returns'].std() * np.sqrt(252)\n",
    "        sharpe = (df['Net_Returns'].mean() / df['Net_Returns'].std()) * np.sqrt(252) if vol > 0 else 0\n",
    "        max_dd = df['Drawdown'].min()\n",
    "        \n",
    "        self.metrics = {\n",
    "            'Total Return': total_ret,\n",
    "            'Sharpe Ratio': sharpe,\n",
    "            'Max Drawdown': max_dd\n",
    "        }\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cee99",
   "metadata": {},
   "source": [
    "## 3.  MODELS (V1-V4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36fd0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV1_Baseline(BaseStrategy):\n",
    "    \"\"\"V1: Fixed FracDiff, Standard GMM.\"\"\"\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['FracDiff'] = FeatureLab.frac_diff_fixed(df['Adj Close'].apply(np.log), d=0.4, window=50)\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df['Returns_Smoothed'] = df['Returns'].rolling(5).mean()\n",
    "        df['Vol_Smoothed'] = df['Volatility'].rolling(5).mean()\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        X = df[['Returns_Smoothed', 'Vol_Smoothed']].values\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "        df['Cluster'] = gmm.fit_predict(X_scaled)\n",
    "        \n",
    "        stats = df.groupby('Cluster')['Returns_Smoothed'].mean().sort_values().index\n",
    "        mapping = {stats[0]: -1, stats[1]: 0, stats[2]: 1}\n",
    "        df['Regime'] = df['Cluster'].map(mapping)\n",
    "        \n",
    "        df['Signal'] = 0\n",
    "        df.loc[(df['Regime'] == 1) & (df['FracDiff'] > 0), 'Signal'] = 1\n",
    "        df.loc[(df['Regime'] == 0) & (df['RSI'] < 40), 'Signal'] = 1\n",
    "        \n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Vol_Scaler'] = (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        df['Signal'] = df['Signal'] * df['Vol_Scaler']\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d053d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV2_Advanced(BaseStrategy):\n",
    "    \"\"\"V2: Rolling GMM.\"\"\"\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['FracDiff'] = FeatureLab.frac_diff_fixed(df['Adj Close'].apply(np.log), d=0.4, window=50)\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df['Returns_Smoothed'] = df['Returns'].rolling(5).mean()\n",
    "        df['Vol_Smoothed'] = df['Volatility'].rolling(5).mean()\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        df['Regime'] = 0\n",
    "        window_size, step_size = 504, 126\n",
    "        preds, indices = [], []\n",
    "        \n",
    "        if len(df) > window_size:\n",
    "            for t in range(window_size, len(df), step_size):\n",
    "                train = df.iloc[t-window_size:t]\n",
    "                test = df.iloc[t:t+step_size]\n",
    "                if test.empty: break\n",
    "                \n",
    "                scaler = StandardScaler()\n",
    "                X_train_s = scaler.fit_transform(train[['Returns_Smoothed', 'Vol_Smoothed']].values)\n",
    "                X_test_s = scaler.transform(test[['Returns_Smoothed', 'Vol_Smoothed']].values)\n",
    "                \n",
    "                gmm = GaussianMixture(n_components=3, random_state=42).fit(X_train_s)\n",
    "                train['Clust'] = gmm.predict(X_train_s)\n",
    "                stats = train.groupby('Clust')['Returns_Smoothed'].mean().sort_values().index\n",
    "                mapping = {stats[0]: -1, stats[1]: 0, stats[2]: 1}\n",
    "                \n",
    "                preds.extend([mapping[x] for x in gmm.predict(X_test_s)])\n",
    "                indices.extend(test.index)\n",
    "            \n",
    "            df.loc[indices, 'Regime'] = pd.Series(preds, index=indices)\n",
    "        \n",
    "        df['Signal'] = 0\n",
    "        df.loc[(df['Regime'] == 1) & (df['FracDiff'] > 0), 'Signal'] = 1\n",
    "        df.loc[(df['Regime'] == 0) & (df['RSI'] < 45), 'Signal'] = 1\n",
    "        \n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Vol_Scaler'] = (target_vol / df['Volatility']).clip(upper=1.0)\n",
    "        df['Signal'] = df['Signal'] * df['Vol_Scaler']\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9445384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV3_Macro(BaseStrategy):\n",
    "    \"\"\"V3: Macro (SPY) Filter.\"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.spy_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        super().fetch_data(warmup_years)\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\") - timedelta(days=warmup_years*365)\n",
    "        try:\n",
    "            spy = yf.download(\"SPY\", start=start_dt.strftime(\"%Y-%m-%d\"), end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(spy.columns, pd.MultiIndex): spy.columns = spy.columns.get_level_values(0)\n",
    "            self.spy_data = spy[['Adj Close']].rename(columns={'Adj Close': 'SPY_Price'})\n",
    "        except: pass\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        if self.spy_data is not None:\n",
    "            df = df.join(self.spy_data, how='left')\n",
    "            df['SPY_MA200'] = df['SPY_Price'].rolling(window=200).mean()\n",
    "            df['Macro_Bull'] = df['SPY_Price'] > df['SPY_MA200']\n",
    "        else:\n",
    "            df['Macro_Bull'] = True\n",
    "            \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['FracDiff'] = FeatureLab.frac_diff_fixed(df['Adj Close'].apply(np.log), d=0.4, window=50)\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        df['Signal'] = 0\n",
    "        df.loc[(df['FracDiff'] > 0), 'Signal'] = 1\n",
    "        df.loc[df['Macro_Bull'] == False, 'Signal'] = 0\n",
    "        \n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Signal'] = df['Signal'] * (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2049efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV4_Meta(BaseStrategy):\n",
    "    \"\"\"V4: Dynamic Profiling with OBV.\"\"\"\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['FracDiff'] = FeatureLab.frac_diff_fixed(df['Adj Close'].apply(np.log), d=0.4, window=50)\n",
    "        df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()\n",
    "        df['OBV_Trend'] = df['OBV'].rolling(50).mean()\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        df['Signal'] = 0\n",
    "        # Trend\n",
    "        df.loc[(df['FracDiff'] > 0) & (df['OBV'] > df['OBV_Trend']), 'Signal'] = 1\n",
    "        # Reversion\n",
    "        df.loc[(df['RSI'] < 30), 'Signal'] = 1\n",
    "        \n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Signal'] = df['Signal'] * (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa87be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV5_KalmanState(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V5 (Formerly V10): Kalman Filter + Macro Filter + Volatility Burst Control.\n",
    "    Uses Kalman Filter for noise-free slope estimation[cite: 151].\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.spy_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        super().fetch_data(warmup_years)\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\") - timedelta(days=warmup_years*365)\n",
    "        try:\n",
    "            spy = yf.download(\"SPY\", start=start_dt.strftime(\"%Y-%m-%d\"), end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(spy.columns, pd.MultiIndex): spy.columns = spy.columns.get_level_values(0)\n",
    "            spy['Macro_Trend'] = (spy['Adj Close'] > spy['Adj Close'].rolling(200).mean()).astype(int)\n",
    "            self.spy_data = spy[['Macro_Trend']]\n",
    "        except: pass\n",
    "\n",
    "    def _apply_kalman_filter(self, prices):\n",
    "        x = prices.values\n",
    "        n = len(x)\n",
    "        state = np.zeros(n)\n",
    "        slope = np.zeros(n)\n",
    "        state[0] = x[0]\n",
    "        P, Q, R = 1.0, 0.001, 0.1\n",
    "        \n",
    "        for t in range(1, n):\n",
    "            pred_state = state[t-1] + slope[t-1]\n",
    "            pred_P = P + Q\n",
    "            measurement = x[t]\n",
    "            residual = measurement - pred_state\n",
    "            K = pred_P / (pred_P + R)\n",
    "            state[t] = pred_state + K * residual\n",
    "            slope[t] = 0.9 * slope[t-1] + 0.1 * (state[t] - state[t-1])\n",
    "            P = (1 - K) * pred_P\n",
    "        return pd.Series(slope, index=prices.index)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        if self.spy_data is not None:\n",
    "            df = df.join(self.spy_data, how='left').fillna(method='ffill')\n",
    "        else:\n",
    "            df['Macro_Trend'] = 1 \n",
    "            \n",
    "        log_prices = np.log(df['Adj Close'])\n",
    "        df['Kalman_Slope'] = self._apply_kalman_filter(log_prices)\n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['Vol_Change'] = df['Volatility'].diff()\n",
    "        \n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # Primary Logic\n",
    "        df['Signal'] = 0.0\n",
    "        long_condition = (df['Kalman_Slope'] > 0) & (df['Macro_Trend'] == 1)\n",
    "        df.loc[long_condition, 'Signal'] = 1\n",
    "        \n",
    "        # Vol Targeting & Burst Protection\n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Vol_Scaler'] = (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        \n",
    "        vol_spike = df['Vol_Change'] > df['Vol_Change'].rolling(20).std() * 2\n",
    "        df.loc[vol_spike, 'Vol_Scaler'] *= 0.5\n",
    "        df.loc[df['Macro_Trend'] == 0, 'Vol_Scaler'] *= 0.5\n",
    "        \n",
    "        df['Signal'] = df['Signal'] * df['Vol_Scaler']\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9ae392",
   "metadata": {},
   "source": [
    "## 4. NEW MODEL: STRATEGY V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd4e1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV6_MetaLabeling(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V6: The Institutional Standard.\n",
    "    1. Primary Model: Kalman Filter (same as V5).\n",
    "    2. Meta-Labeling: Random Forest validates signals.\n",
    "    3. Target: Triple Barrier Method (Profit/Loss/Time).\n",
    "    4. Sizing: Kelly Criterion approximation (Probability-based).\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.spy_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        super().fetch_data(warmup_years)\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\") - timedelta(days=warmup_years*365)\n",
    "        try:\n",
    "            spy = yf.download(\"SPY\", start=start_dt.strftime(\"%Y-%m-%d\"), end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(spy.columns, pd.MultiIndex): spy.columns = spy.columns.get_level_values(0)\n",
    "            spy['Macro_Trend'] = (spy['Adj Close'] > spy['Adj Close'].rolling(200).mean()).astype(int)\n",
    "            self.spy_data = spy[['Macro_Trend']]\n",
    "        except: pass\n",
    "\n",
    "    def _apply_kalman_filter(self, prices):\n",
    "        x = prices.values\n",
    "        n = len(x)\n",
    "        state = np.zeros(n)\n",
    "        slope = np.zeros(n)\n",
    "        state[0] = x[0]\n",
    "        P, Q, R = 1.0, 0.001, 0.1\n",
    "        for t in range(1, n):\n",
    "            pred_state = state[t-1] + slope[t-1]\n",
    "            pred_P = P + Q\n",
    "            measurement = x[t]\n",
    "            residual = measurement - pred_state\n",
    "            K = pred_P / (pred_P + R)\n",
    "            state[t] = pred_state + K * residual\n",
    "            slope[t] = 0.9 * slope[t-1] + 0.1 * (state[t] - state[t-1])\n",
    "            P = (1 - K) * pred_P\n",
    "        return pd.Series(slope, index=prices.index)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # 1. Macro & Features\n",
    "        if self.spy_data is not None:\n",
    "            df = df.join(self.spy_data, how='left').fillna(method='ffill')\n",
    "        else: df['Macro_Trend'] = 1\n",
    "            \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['Kalman_Slope'] = self._apply_kalman_filter(np.log(df['Adj Close']))\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df['Spread'] = df['Adj Close'] - df['Adj Close'].rolling(20).mean() # Mean Reversion feature\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # 2. Primary Signal (The Candidate Generator)\n",
    "        df['Primary_Signal'] = 0\n",
    "        df.loc[(df['Kalman_Slope'] > 0) & (df['Macro_Trend'] == 1), 'Primary_Signal'] = 1\n",
    "        \n",
    "        # 3. Triple Barrier Labels (The Teacher)\n",
    "        # We assume Profit Take = 1 StdDev, Stop Loss = 1 StdDev\n",
    "        labels = FeatureLab.triple_barrier_labels(df['Adj Close'], df['Volatility'], pt=1.0, sl=1.0, barrier_window=10)\n",
    "        \n",
    "        # 4. Walk-Forward Meta-Model Training\n",
    "        # We cannot just train on all data (Look-ahead bias). We must simulate real-time.\n",
    "        df['Meta_Prob'] = 0.5 # Default neutral\n",
    "        \n",
    "        # Hyperparameters\n",
    "        train_window = 252 * 2 # 2 Years training\n",
    "        update_freq = 63       # Retrain every quarter\n",
    "        \n",
    "        clf = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42)\n",
    "        feature_cols = ['Volatility', 'RSI', 'Spread', 'Kalman_Slope']\n",
    "        \n",
    "        # Walk-Forward Loop\n",
    "        indices = df.index\n",
    "        if len(df) > train_window:\n",
    "            for t in range(train_window, len(df), update_freq):\n",
    "                # Define windows\n",
    "                train_start = indices[t - train_window]\n",
    "                train_end = indices[t]\n",
    "                test_end_idx = min(t + update_freq, len(df))\n",
    "                test_end = indices[test_end_idx - 1]\n",
    "                \n",
    "                # Train Data\n",
    "                X_train = df.loc[train_start:train_end, feature_cols]\n",
    "                y_train = labels.loc[train_start:train_end]\n",
    "                \n",
    "                # Filter: We only care about instances where Primary Signal was active!\n",
    "                # Meta-Labeling answers: \"Given Primary says Buy, should we?\"\n",
    "                # However, for simplicity/robustness, we can train on all data to learn market dynamics\n",
    "                # or filter. Research suggests filtering.\n",
    "                train_mask = (df.loc[train_start:train_end, 'Primary_Signal'] != 0)\n",
    "                if train_mask.sum() > 20: # Only train if enough samples\n",
    "                    clf.fit(X_train.loc[train_mask], y_train.loc[train_mask])\n",
    "                    \n",
    "                    # Predict for next window\n",
    "                    X_test = df.loc[train_end:test_end, feature_cols]\n",
    "                    # Prob of Class 1 (Profit)\n",
    "                    probs = clf.predict_proba(X_test)[:, 1] \n",
    "                    df.loc[train_end:test_end, 'Meta_Prob'] = probs\n",
    "        \n",
    "        # 5. Final Signal Construction\n",
    "        # If Primary says Buy AND Meta Model Prob > 0.55 -> BUY\n",
    "        df['Signal'] = 0.0\n",
    "        # High Confidence Signal\n",
    "        valid_buy = (df['Primary_Signal'] == 1) & (df['Meta_Prob'] > 0.55)\n",
    "        df.loc[valid_buy, 'Signal'] = 1\n",
    "        \n",
    "        # 6. Kelly-Style Sizing [cite: 238]\n",
    "        # Size proportional to (Probability - 0.5)\n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        vol_scaler = (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        \n",
    "        # Probability scaler: 0.55 prob -> 1x, 0.75 prob -> 1.5x\n",
    "        prob_scaler = (df['Meta_Prob'] - 0.5) * 10 \n",
    "        prob_scaler = prob_scaler.clip(0.5, 1.5)\n",
    "        \n",
    "        df['Signal'] = df['Signal'] * vol_scaler * prob_scaler\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f9598e",
   "metadata": {},
   "source": [
    "## 5. ROBUST BENCHMARK INFRASTRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "285c817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustBenchmark:\n",
    "    \"\"\"\n",
    "    Implements Walk-Forward Analysis and Deflated Sharpe Ratio logic.\n",
    "    Benchmarks multiple strategies without look-ahead bias[cite: 275].\n",
    "    \"\"\"\n",
    "    def __init__(self, tickers, start_date, end_date):\n",
    "        self.tickers = tickers\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.results = []\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"{'STRATEGY':<10} | {'TICKER':<6} | {'ANN RET':<7} | {'SHARPE':<6} | {'MAX DD':<7} | {'NOTES'}\")\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        strategies = {\n",
    "            \"V1_Base\": StrategyV1_Baseline,\n",
    "            \"V2_GMM\": StrategyV2_Advanced,\n",
    "            \"V3_Macro\": StrategyV3_Macro,\n",
    "            \"V4_Meta\": StrategyV4_Meta,\n",
    "            \"V5_Kalman\": StrategyV5_KalmanState,\n",
    "            \"V6_Inst\": StrategyV6_MetaLabeling\n",
    "        }\n",
    "\n",
    "        for ticker in self.tickers:\n",
    "            # Capture Buy & Hold first\n",
    "            bh = StrategyV1_Baseline(ticker, self.start_date, self.end_date)\n",
    "            bh.fetch_data()\n",
    "            bh.data['Signal'] = 1 # Force Buy\n",
    "            bh.run_backtest()\n",
    "            self._print_row(\"Buy&Hold\", ticker, bh.metrics)\n",
    "            \n",
    "            for name, StratClass in strategies.items():\n",
    "                try:\n",
    "                    strat = StratClass(ticker, self.start_date, self.end_date)\n",
    "                    strat.fetch_data(warmup_years=2)\n",
    "                    strat.generate_signals()\n",
    "                    strat.run_backtest()\n",
    "                    \n",
    "                    self._print_row(name, ticker, strat.metrics)\n",
    "                    \n",
    "                    # Store for portfolio level (optional)\n",
    "                    self.results.append({\n",
    "                        'Ticker': ticker,\n",
    "                        'Strategy': name,\n",
    "                        'Returns': strat.results['Net_Returns']\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed {name} {ticker}: {e}\")\n",
    "            print(\"-\" * 75)\n",
    "\n",
    "    def _print_row(self, name, ticker, metrics):\n",
    "        if not metrics: return\n",
    "        ret = metrics['Total Return']\n",
    "        # Annualize return approx\n",
    "        ann_ret = (1 + ret) ** (252 / len(metrics.get('Returns', [1]*252))) - 1 if 'Returns' in metrics else ret\n",
    "        print(f\"{name:<10} | {ticker:<6} | {ret:.1%}   | {metrics['Sharpe Ratio']:.2f}   | {metrics['Max Drawdown']:.1%}   |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c992984",
   "metadata": {},
   "source": [
    "## 6. EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd7744c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRATEGY   | TICKER | ANN RET | SHARPE | MAX DD  | NOTES\n",
      "---------------------------------------------------------------------------\n",
      "Buy&Hold   | NVDA   | 946.9%   | 1.38   | -66.3%   |\n",
      "V1_Base    | NVDA   | 50.0%   | 1.19   | -6.9%   |\n",
      "V2_GMM     | NVDA   | 100.7%   | 1.17   | -10.9%   |\n",
      "V3_Macro   | NVDA   | 357.9%   | 1.61   | -25.6%   |\n",
      "V4_Meta    | NVDA   | 354.4%   | 1.63   | -23.8%   |\n",
      "V5_Kalman  | NVDA   | 149.7%   | 1.18   | -20.5%   |\n",
      "V6_Inst    | NVDA   | 40.9%   | 0.51   | -25.8%   |\n",
      "---------------------------------------------------------------------------\n",
      "Buy&Hold   | SPY    | 70.7%   | 0.90   | -24.5%   |\n",
      "V1_Base    | SPY    | 94.6%   | 1.06   | -20.2%   |\n",
      "V2_GMM     | SPY    | 14.9%   | 0.37   | -18.9%   |\n",
      "V3_Macro   | SPY    | 94.7%   | 1.11   | -25.6%   |\n",
      "V4_Meta    | SPY    | 32.0%   | 0.55   | -17.7%   |\n",
      "V5_Kalman  | SPY    | 70.4%   | 1.07   | -18.3%   |\n",
      "V6_Inst    | SPY    | 31.3%   | 0.57   | -19.6%   |\n",
      "---------------------------------------------------------------------------\n",
      "Buy&Hold   | JPM    | 113.5%   | 0.91   | -38.8%   |\n",
      "V1_Base    | JPM    | 85.3%   | 0.92   | -27.6%   |\n",
      "V2_GMM     | JPM    | 16.8%   | 0.34   | -17.3%   |\n",
      "V3_Macro   | JPM    | 110.5%   | 0.98   | -31.5%   |\n",
      "V4_Meta    | JPM    | 102.6%   | 1.03   | -21.7%   |\n",
      "V5_Kalman  | JPM    | 6.4%   | 0.18   | -36.7%   |\n",
      "V6_Inst    | JPM    | 13.1%   | 0.29   | -20.6%   |\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test on a mix of Volatility (TSLA) and Stability (KO) and Tech (NVDA)\n",
    "# encompassing the 2022 Bear and 2023-24 Bull\n",
    "bench = RobustBenchmark(\n",
    "    tickers=[\"NVDA\", \"SPY\", \"JPM\"], \n",
    "    start_date=\"2021-01-01\", \n",
    "    end_date=\"2024-12-30\"\n",
    ")\n",
    "bench.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
