{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4be3e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from abc import ABC, abstractmethod\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db667cc",
   "metadata": {},
   "source": [
    "## 1. FEATURE ENGINEERING LAB (The Math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14adbb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureLab:\n",
    "    \"\"\"Shared mathematical engine for technical and statistical features.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_weights_frac_diff(d, size, threshold=1e-5):\n",
    "        w = [1.0]\n",
    "        for k in range(1, size):\n",
    "            w_k = -w[-1] / k * (d - k + 1)\n",
    "            w.append(w_k)\n",
    "        w = np.array(w[::-1])\n",
    "        w = w[np.abs(w) > threshold]\n",
    "        return w\n",
    "\n",
    "    @staticmethod\n",
    "    def frac_diff_fixed(series, d, window=50):\n",
    "        # Solves Stationarity Dilemma [cite: 61]\n",
    "        weights = FeatureLab.get_weights_frac_diff(d, window)\n",
    "        res = series.rolling(window=len(weights)).apply(lambda x: np.dot(x, weights), raw=True)\n",
    "        return res\n",
    "\n",
    "    @staticmethod\n",
    "    def yang_zhang_volatility(df, window=30):\n",
    "        # Captures intraday energy/gaps [cite: 82]\n",
    "        log_ho = (df['High'] / df['Open']).apply(np.log)\n",
    "        log_lo = (df['Low'] / df['Open']).apply(np.log)\n",
    "        log_co = (df['Close'] / df['Open']).apply(np.log)\n",
    "        log_oc = (df['Open'] / df['Close'].shift(1)).apply(np.log)\n",
    "        log_cc = (df['Close'] / df['Close'].shift(1)).apply(np.log)\n",
    "        \n",
    "        rs = log_ho * (log_ho - log_co) + log_lo * (log_lo - log_co)\n",
    "        close_vol = log_cc.rolling(window=window).var()\n",
    "        open_vol = log_oc.rolling(window=window).var()\n",
    "        window_rs = rs.rolling(window=window).mean()\n",
    "\n",
    "        k = 0.34 / (1.34 + (window + 1) / (window - 1))\n",
    "        return np.sqrt(open_vol + k * window_rs)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_rsi(series, window=14):\n",
    "        delta = series.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "        rs = gain / loss\n",
    "        return 100 - (100 / (1 + rs))\n",
    "\n",
    "    @staticmethod\n",
    "    def triple_barrier_labels(prices, vol, pt=1.0, sl=1.0, barrier_window=10):\n",
    "        \"\"\"\n",
    "        Implements the Triple Barrier Method.\n",
    "        Labels: 1 (Profit Target Hit), -1 (Stop Loss Hit), 0 (Time Limit/Neutral)\n",
    "        \"\"\"\n",
    "        labels = pd.Series(0, index=prices.index)\n",
    "        # Shift prices to align future outcome with current row\n",
    "        # However, to avoid look-ahead in features, we usually compute label for row t based on t+1...t+k\n",
    "        # This function generates the TARGET variable (y) for training.\n",
    "        \n",
    "        limit = len(prices) - barrier_window\n",
    "        p_values = prices.values\n",
    "        v_values = vol.values\n",
    "        \n",
    "        for i in range(limit):\n",
    "            current_p = p_values[i]\n",
    "            current_vol = v_values[i]\n",
    "            \n",
    "            # Dynamic barriers based on volatility [cite: 215]\n",
    "            target = current_p * (1 + pt * current_vol)\n",
    "            stop = current_p * (1 - sl * current_vol)\n",
    "            \n",
    "            future_window = p_values[i+1 : i+1+barrier_window]\n",
    "            \n",
    "            hit_target = np.where(future_window >= target)[0]\n",
    "            hit_stop = np.where(future_window <= stop)[0]\n",
    "            \n",
    "            first_target = hit_target[0] if len(hit_target) > 0 else barrier_window + 1\n",
    "            first_stop = hit_stop[0] if len(hit_stop) > 0 else barrier_window + 1\n",
    "            \n",
    "            if first_target < first_stop and first_target <= barrier_window:\n",
    "                labels.iloc[i] = 1\n",
    "            elif first_stop < first_target and first_stop <= barrier_window:\n",
    "                labels.iloc[i] = 0 # In Meta-Labeling, we often treat Stop (-1) as 0 (Do Not Trade)\n",
    "            # Else 0 (Time limit reached or neutral)\n",
    "            \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40668a35",
   "metadata": {},
   "source": [
    "## 2. BASE STRATEGY INFRASTRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5398e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseStrategy(ABC):\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        self.ticker = ticker\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.data = None\n",
    "        self.results = None\n",
    "        self.metrics = {}\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\")\n",
    "        warmup_start_dt = start_dt - timedelta(days=warmup_years*365)\n",
    "        warmup_start_str = warmup_start_dt.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        try:\n",
    "            self.data = yf.download(self.ticker, start=warmup_start_str, end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(self.data.columns, pd.MultiIndex): \n",
    "                self.data.columns = self.data.columns.get_level_values(0)\n",
    "            if 'Adj Close' not in self.data.columns: \n",
    "                self.data['Adj Close'] = self.data['Close']\n",
    "            self.data['Returns'] = self.data['Adj Close'].pct_change()\n",
    "            self.data.dropna(inplace=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {self.ticker}: {e}\")\n",
    "            self.data = pd.DataFrame()\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate_signals(self):\n",
    "        pass\n",
    "\n",
    "    def run_backtest(self, transaction_cost=0.0005, rebalance_threshold=0.1):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        \n",
    "        backtest_mask = self.data.index >= self.start_date\n",
    "        df = self.data.loc[backtest_mask].copy()\n",
    "        if df.empty: return\n",
    "\n",
    "        # Position Smoothing\n",
    "        clean_positions = []\n",
    "        current_pos = 0.0\n",
    "        raw_signals = df['Signal'].values\n",
    "        \n",
    "        for target in raw_signals:\n",
    "            if abs(target - current_pos) > rebalance_threshold:\n",
    "                current_pos = target\n",
    "            clean_positions.append(current_pos)\n",
    "            \n",
    "        df['Position'] = clean_positions\n",
    "        df['Prev_Position'] = df['Position'].shift(1).fillna(0)\n",
    "        df['Turnover'] = (df['Prev_Position'] - df['Position'].shift(2).fillna(0)).abs()\n",
    "        df['Gross_Returns'] = df['Prev_Position'] * df['Returns']\n",
    "        df['Net_Returns'] = df['Gross_Returns'] - (df['Turnover'] * transaction_cost)\n",
    "        df['Net_Returns'].fillna(0, inplace=True)\n",
    "        \n",
    "        df['Cumulative_Strategy'] = (1 + df['Net_Returns']).cumprod()\n",
    "        df['Cumulative_Market'] = (1 + df['Returns']).cumprod()\n",
    "        \n",
    "        roll_max = df['Cumulative_Strategy'].cummax()\n",
    "        df['Drawdown'] = (df['Cumulative_Strategy'] / roll_max) - 1.0\n",
    "        \n",
    "        self.results = df\n",
    "        \n",
    "        # Performance Calculation\n",
    "        total_ret = df['Cumulative_Strategy'].iloc[-1] - 1\n",
    "        vol = df['Net_Returns'].std() * np.sqrt(252)\n",
    "        sharpe = (df['Net_Returns'].mean() / df['Net_Returns'].std()) * np.sqrt(252) if vol > 0 else 0\n",
    "        max_dd = df['Drawdown'].min()\n",
    "        \n",
    "        self.metrics = {\n",
    "            'Total Return': total_ret,\n",
    "            'Sharpe Ratio': sharpe,\n",
    "            'Max Drawdown': max_dd\n",
    "        }\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cee99",
   "metadata": {},
   "source": [
    "## 3.  MODELS (V1-V4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36fd0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV1_Baseline(BaseStrategy):\n",
    "    \"\"\"V1: Fixed FracDiff, Standard GMM.\"\"\"\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['FracDiff'] = FeatureLab.frac_diff_fixed(df['Adj Close'].apply(np.log), d=0.4, window=50)\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df['Returns_Smoothed'] = df['Returns'].rolling(5).mean()\n",
    "        df['Vol_Smoothed'] = df['Volatility'].rolling(5).mean()\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        X = df[['Returns_Smoothed', 'Vol_Smoothed']].values\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "        df['Cluster'] = gmm.fit_predict(X_scaled)\n",
    "        \n",
    "        stats = df.groupby('Cluster')['Returns_Smoothed'].mean().sort_values().index\n",
    "        mapping = {stats[0]: -1, stats[1]: 0, stats[2]: 1}\n",
    "        df['Regime'] = df['Cluster'].map(mapping)\n",
    "        \n",
    "        df['Signal'] = 0\n",
    "        df.loc[(df['Regime'] == 1) & (df['FracDiff'] > 0), 'Signal'] = 1\n",
    "        df.loc[(df['Regime'] == 0) & (df['RSI'] < 40), 'Signal'] = 1\n",
    "        \n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Vol_Scaler'] = (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        df['Signal'] = df['Signal'] * df['Vol_Scaler']\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d053d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV2_Advanced(BaseStrategy):\n",
    "    \"\"\"V2: Rolling GMM.\"\"\"\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['FracDiff'] = FeatureLab.frac_diff_fixed(df['Adj Close'].apply(np.log), d=0.4, window=50)\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df['Returns_Smoothed'] = df['Returns'].rolling(5).mean()\n",
    "        df['Vol_Smoothed'] = df['Volatility'].rolling(5).mean()\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        df['Regime'] = 0\n",
    "        window_size, step_size = 504, 126\n",
    "        preds, indices = [], []\n",
    "        \n",
    "        if len(df) > window_size:\n",
    "            for t in range(window_size, len(df), step_size):\n",
    "                train = df.iloc[t-window_size:t]\n",
    "                test = df.iloc[t:t+step_size]\n",
    "                if test.empty: break\n",
    "                \n",
    "                scaler = StandardScaler()\n",
    "                X_train_s = scaler.fit_transform(train[['Returns_Smoothed', 'Vol_Smoothed']].values)\n",
    "                X_test_s = scaler.transform(test[['Returns_Smoothed', 'Vol_Smoothed']].values)\n",
    "                \n",
    "                gmm = GaussianMixture(n_components=3, random_state=42).fit(X_train_s)\n",
    "                train['Clust'] = gmm.predict(X_train_s)\n",
    "                stats = train.groupby('Clust')['Returns_Smoothed'].mean().sort_values().index\n",
    "                mapping = {stats[0]: -1, stats[1]: 0, stats[2]: 1}\n",
    "                \n",
    "                preds.extend([mapping[x] for x in gmm.predict(X_test_s)])\n",
    "                indices.extend(test.index)\n",
    "            \n",
    "            df.loc[indices, 'Regime'] = pd.Series(preds, index=indices)\n",
    "        \n",
    "        df['Signal'] = 0\n",
    "        df.loc[(df['Regime'] == 1) & (df['FracDiff'] > 0), 'Signal'] = 1\n",
    "        df.loc[(df['Regime'] == 0) & (df['RSI'] < 45), 'Signal'] = 1\n",
    "        \n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Vol_Scaler'] = (target_vol / df['Volatility']).clip(upper=1.0)\n",
    "        df['Signal'] = df['Signal'] * df['Vol_Scaler']\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9445384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV3_Macro(BaseStrategy):\n",
    "    \"\"\"V3: Macro (SPY) Filter.\"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.spy_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        super().fetch_data(warmup_years)\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\") - timedelta(days=warmup_years*365)\n",
    "        try:\n",
    "            spy = yf.download(\"SPY\", start=start_dt.strftime(\"%Y-%m-%d\"), end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(spy.columns, pd.MultiIndex): spy.columns = spy.columns.get_level_values(0)\n",
    "            self.spy_data = spy[['Adj Close']].rename(columns={'Adj Close': 'SPY_Price'})\n",
    "        except: pass\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        if self.spy_data is not None:\n",
    "            df = df.join(self.spy_data, how='left')\n",
    "            df['SPY_MA200'] = df['SPY_Price'].rolling(window=200).mean()\n",
    "            df['Macro_Bull'] = df['SPY_Price'] > df['SPY_MA200']\n",
    "        else:\n",
    "            df['Macro_Bull'] = True\n",
    "            \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['FracDiff'] = FeatureLab.frac_diff_fixed(df['Adj Close'].apply(np.log), d=0.4, window=50)\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        df['Signal'] = 0\n",
    "        df.loc[(df['FracDiff'] > 0), 'Signal'] = 1\n",
    "        df.loc[df['Macro_Bull'] == False, 'Signal'] = 0\n",
    "        \n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Signal'] = df['Signal'] * (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2049efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV4_Meta(BaseStrategy):\n",
    "    \"\"\"V4: Dynamic Profiling with OBV.\"\"\"\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['FracDiff'] = FeatureLab.frac_diff_fixed(df['Adj Close'].apply(np.log), d=0.4, window=50)\n",
    "        df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()\n",
    "        df['OBV_Trend'] = df['OBV'].rolling(50).mean()\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        df['Signal'] = 0\n",
    "        # Trend\n",
    "        df.loc[(df['FracDiff'] > 0) & (df['OBV'] > df['OBV_Trend']), 'Signal'] = 1\n",
    "        # Reversion\n",
    "        df.loc[(df['RSI'] < 30), 'Signal'] = 1\n",
    "        \n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Signal'] = df['Signal'] * (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7fa87be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV5_KalmanState(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V5 (Formerly V10): Kalman Filter + Macro Filter + Volatility Burst Control.\n",
    "    Uses Kalman Filter for noise-free slope estimation[cite: 151].\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.spy_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        super().fetch_data(warmup_years)\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\") - timedelta(days=warmup_years*365)\n",
    "        try:\n",
    "            spy = yf.download(\"SPY\", start=start_dt.strftime(\"%Y-%m-%d\"), end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(spy.columns, pd.MultiIndex): spy.columns = spy.columns.get_level_values(0)\n",
    "            spy['Macro_Trend'] = (spy['Adj Close'] > spy['Adj Close'].rolling(200).mean()).astype(int)\n",
    "            self.spy_data = spy[['Macro_Trend']]\n",
    "        except: pass\n",
    "\n",
    "    def _apply_kalman_filter(self, prices):\n",
    "        x = prices.values\n",
    "        n = len(x)\n",
    "        state = np.zeros(n)\n",
    "        slope = np.zeros(n)\n",
    "        state[0] = x[0]\n",
    "        P, Q, R = 1.0, 0.001, 0.1\n",
    "        \n",
    "        for t in range(1, n):\n",
    "            pred_state = state[t-1] + slope[t-1]\n",
    "            pred_P = P + Q\n",
    "            measurement = x[t]\n",
    "            residual = measurement - pred_state\n",
    "            K = pred_P / (pred_P + R)\n",
    "            state[t] = pred_state + K * residual\n",
    "            slope[t] = 0.9 * slope[t-1] + 0.1 * (state[t] - state[t-1])\n",
    "            P = (1 - K) * pred_P\n",
    "        return pd.Series(slope, index=prices.index)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        if self.spy_data is not None:\n",
    "            df = df.join(self.spy_data, how='left').fillna(method='ffill')\n",
    "        else:\n",
    "            df['Macro_Trend'] = 1 \n",
    "            \n",
    "        log_prices = np.log(df['Adj Close'])\n",
    "        df['Kalman_Slope'] = self._apply_kalman_filter(log_prices)\n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['Vol_Change'] = df['Volatility'].diff()\n",
    "        \n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # Primary Logic\n",
    "        df['Signal'] = 0.0\n",
    "        long_condition = (df['Kalman_Slope'] > 0) & (df['Macro_Trend'] == 1)\n",
    "        df.loc[long_condition, 'Signal'] = 1\n",
    "        \n",
    "        # Vol Targeting & Burst Protection\n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        df['Vol_Scaler'] = (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        \n",
    "        vol_spike = df['Vol_Change'] > df['Vol_Change'].rolling(20).std() * 2\n",
    "        df.loc[vol_spike, 'Vol_Scaler'] *= 0.5\n",
    "        df.loc[df['Macro_Trend'] == 0, 'Vol_Scaler'] *= 0.5\n",
    "        \n",
    "        df['Signal'] = df['Signal'] * df['Vol_Scaler']\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9ae392",
   "metadata": {},
   "source": [
    "## 4. NEW MODEL: STRATEGY V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd4e1e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV6_MetaLabeling(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V6.1 (Hybrid): The 'Regime-Adaptive' Institutional Model.\n",
    "    \n",
    "    Architecture:\n",
    "    1. Primary Signal (Hybrid): \n",
    "       - TREND: Kalman Slope > 0 (Catch the run)\n",
    "       - VALUE: RSI < 30 (Catch the dip)\n",
    "       This ensures we have candidates in both trending and chopping markets.\n",
    "       \n",
    "    2. Meta-Labeling (Random Forest): \n",
    "       - Learns WHICH of the above signals works for the current asset/regime.\n",
    "       \n",
    "    3. Soft-Sizing: Scales leverage based on ML confidence.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.spy_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        super().fetch_data(warmup_years)\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\") - timedelta(days=warmup_years*365)\n",
    "        try:\n",
    "            spy = yf.download(\"SPY\", start=start_dt.strftime(\"%Y-%m-%d\"), end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(spy.columns, pd.MultiIndex): spy.columns = spy.columns.get_level_values(0)\n",
    "            spy['Macro_Trend'] = (spy['Adj Close'] > spy['Adj Close'].rolling(200).mean()).astype(int)\n",
    "            self.spy_data = spy[['Macro_Trend']]\n",
    "        except: pass\n",
    "\n",
    "    def _apply_kalman_filter(self, prices):\n",
    "        x = prices.values\n",
    "        n = len(x)\n",
    "        state = np.zeros(n)\n",
    "        slope = np.zeros(n)\n",
    "        state[0] = x[0]\n",
    "        # Kalman Params\n",
    "        P, Q, R = 1.0, 0.001, 0.1 \n",
    "        \n",
    "        for t in range(1, n):\n",
    "            pred_state = state[t-1] + slope[t-1]\n",
    "            pred_P = P + Q\n",
    "            measurement = x[t]\n",
    "            residual = measurement - pred_state\n",
    "            \n",
    "            K = pred_P / (pred_P + R)\n",
    "            state[t] = pred_state + K * residual\n",
    "            slope[t] = 0.9 * slope[t-1] + 0.1 * (state[t] - state[t-1])\n",
    "            P = (1 - K) * pred_P\n",
    "            \n",
    "        return pd.Series(slope, index=prices.index)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # --- 1. Features ---\n",
    "        if self.spy_data is not None:\n",
    "            df = df.join(self.spy_data, how='left').fillna(method='ffill')\n",
    "        else: df['Macro_Trend'] = 1\n",
    "            \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['Kalman_Slope'] = self._apply_kalman_filter(np.log(df['Adj Close']))\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df['Spread'] = df['Adj Close'] - df['Adj Close'].rolling(20).mean()\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # --- 2. Primary Signal (The Hybrid Generator) ---\n",
    "        df['Primary_Signal'] = 0\n",
    "        \n",
    "        # A. MOMENTUM LEG (For NVDA/SPY)\n",
    "        # Catch the trend when slope is positive\n",
    "        trend_signal = (df['Kalman_Slope'] > 0)\n",
    "        \n",
    "        # B. MEAN REVERSION LEG (For JPM/Chop)\n",
    "        # Catch the knife when oversold (Value)\n",
    "        value_signal = (df['RSI'] < 30)\n",
    "        \n",
    "        # Combine: We are interested if EITHER is true\n",
    "        df.loc[trend_signal | value_signal, 'Primary_Signal'] = 1\n",
    "        \n",
    "        # --- 3. Meta-Labeling (The Validator) ---\n",
    "        # Label: Did buying here result in profit?\n",
    "        labels = FeatureLab.triple_barrier_labels(df['Adj Close'], df['Volatility'], pt=1.0, sl=1.0, barrier_window=10)\n",
    "        \n",
    "        df['Meta_Prob'] = 0.5\n",
    "        train_window = 252 * 2\n",
    "        update_freq = 63 \n",
    "        \n",
    "        clf = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42)\n",
    "        feature_cols = ['Volatility', 'RSI', 'Spread', 'Kalman_Slope']\n",
    "        \n",
    "        indices = df.index\n",
    "        if len(df) > train_window:\n",
    "            for t in range(train_window, len(df), update_freq):\n",
    "                train_start = indices[t - train_window]\n",
    "                train_end = indices[t]\n",
    "                test_end_idx = min(t + update_freq, len(df))\n",
    "                test_end = indices[test_end_idx - 1]\n",
    "                \n",
    "                X_train = df.loc[train_start:train_end, feature_cols]\n",
    "                y_train = labels.loc[train_start:train_end]\n",
    "                \n",
    "                # Training on all data allows the model to learn \"High RSI = Good\" for NVDA\n",
    "                # and \"Low RSI = Good\" for JPM automatically based on recent history.\n",
    "                clf.fit(X_train, y_train)\n",
    "                \n",
    "                X_test = df.loc[train_end:test_end, feature_cols]\n",
    "                probs = clf.predict_proba(X_test)\n",
    "                \n",
    "                if probs.shape[1] == 2:\n",
    "                    pos_probs = probs[:, 1]\n",
    "                else:\n",
    "                    pos_probs = probs[:, 0] if clf.classes_[0] == 1 else 0.0\n",
    "                    \n",
    "                df.loc[train_end:test_end, 'Meta_Prob'] = pos_probs\n",
    "        \n",
    "        # --- 4. Signal Construction ---\n",
    "        df['Signal'] = 0.0\n",
    "        \n",
    "        # Confidence Floor: \n",
    "        # If the ML confirms the hybrid signal (Prob > 0.45), we execute.\n",
    "        # This allows RSI Dips to pass IF the ML thinks they are profitable.\n",
    "        active_trade = (df['Primary_Signal'] == 1) & (df['Meta_Prob'] > 0.45)\n",
    "        df.loc[active_trade, 'Signal'] = 1\n",
    "        \n",
    "        # Sizing (Volatility + Confidence)\n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        vol_scaler = (target_vol / df['Volatility']).clip(upper=2.0)\n",
    "        ml_scaler = (df['Meta_Prob'] / 0.5).clip(0.5, 2.0)\n",
    "        \n",
    "        # Macro Override\n",
    "        # If Bear Market, we are defensive, BUT we allow Deep Value (RSI < 30) \n",
    "        # to have slightly more room if the ML loves it.\n",
    "        macro_scaler = df['Macro_Trend'].map({1: 1.0, 0: 0.5})\n",
    "        \n",
    "        df['Signal'] = df['Signal'] * vol_scaler * ml_scaler * macro_scaler\n",
    "        \n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94a7c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyV7_AdaptiveOptim(BaseStrategy):\n",
    "    \"\"\"\n",
    "    V7 (WFO): Walk-Forward Optimized Strategy.\n",
    "    \n",
    "    Instead of static rules, this strategy runs a 'Tournament' every quarter.\n",
    "    It tests 4 distinct parameter sets (Profiles) on the past 252 days:\n",
    "    \n",
    "    1. Trend_Aggro: Kalman Slope > 0 (No Macro Filter)\n",
    "    2. Trend_Defense: Kalman Slope > 0 AND Macro_Bull (Like V3)\n",
    "    3. Reversion_Deep: RSI < 30 (Buying Crashes)\n",
    "    4. Reversion_Active: RSI < 45 (Buying Dips)\n",
    "    \n",
    "    It selects the Profile with the highest Sharpe Ratio in the lookback window\n",
    "    and uses it for the next execution window.\n",
    "    \"\"\"\n",
    "    def __init__(self, ticker, start_date, end_date):\n",
    "        super().__init__(ticker, start_date, end_date)\n",
    "        self.spy_data = None\n",
    "\n",
    "    def fetch_data(self, warmup_years=2):\n",
    "        super().fetch_data(warmup_years)\n",
    "        start_dt = datetime.strptime(self.start_date, \"%Y-%m-%d\") - timedelta(days=warmup_years*365)\n",
    "        try:\n",
    "            spy = yf.download(\"SPY\", start=start_dt.strftime(\"%Y-%m-%d\"), end=self.end_date, progress=False, auto_adjust=False)\n",
    "            if isinstance(spy.columns, pd.MultiIndex): spy.columns = spy.columns.get_level_values(0)\n",
    "            spy['Macro_Trend'] = (spy['Adj Close'] > spy['Adj Close'].rolling(200).mean()).astype(int)\n",
    "            self.spy_data = spy[['Macro_Trend']]\n",
    "        except: pass\n",
    "\n",
    "    def _apply_kalman_filter(self, prices):\n",
    "        x = prices.values\n",
    "        n = len(x)\n",
    "        state = np.zeros(n)\n",
    "        slope = np.zeros(n)\n",
    "        state[0] = x[0]\n",
    "        P, Q, R = 1.0, 0.01, 0.1 # Q=0.01 makes it slightly more responsive than V6\n",
    "        \n",
    "        for t in range(1, n):\n",
    "            pred_state = state[t-1] + slope[t-1]\n",
    "            pred_P = P + Q\n",
    "            measurement = x[t]\n",
    "            residual = measurement - pred_state\n",
    "            \n",
    "            K = pred_P / (pred_P + R)\n",
    "            state[t] = pred_state + K * residual\n",
    "            slope[t] = 0.9 * slope[t-1] + 0.1 * (state[t] - state[t-1])\n",
    "            P = (1 - K) * pred_P\n",
    "            \n",
    "        return pd.Series(slope, index=prices.index)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        if self.data is None or self.data.empty: return\n",
    "        df = self.data.copy()\n",
    "        \n",
    "        # --- 1. Global Feature Engineering ---\n",
    "        if self.spy_data is not None:\n",
    "            df = df.join(self.spy_data, how='left').fillna(method='ffill')\n",
    "        else: df['Macro_Trend'] = 1\n",
    "            \n",
    "        df['Volatility'] = FeatureLab.yang_zhang_volatility(df)\n",
    "        df['Kalman_Slope'] = self._apply_kalman_filter(np.log(df['Adj Close']))\n",
    "        df['RSI'] = FeatureLab.compute_rsi(df['Adj Close'])\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # --- 2. Pre-Calculate Strategy Candidates (Vectorized) ---\n",
    "        # We calculate the raw signals for all profiles upfront\n",
    "        \n",
    "        # Profile 1: Aggressive Trend (Chase the move)\n",
    "        sig_trend_aggro = (df['Kalman_Slope'] > 0).astype(int)\n",
    "        \n",
    "        # Profile 2: Defensive Trend (V3 Style - Only if Macro agrees)\n",
    "        sig_trend_def = ((df['Kalman_Slope'] > 0) & (df['Macro_Trend'] == 1)).astype(int)\n",
    "        \n",
    "        # Profile 3: Deep Reversion (Catch Falling Knife)\n",
    "        sig_rev_deep = (df['RSI'] < 30).astype(int)\n",
    "        \n",
    "        # Profile 4: Active Reversion (Buy Shallow Dips)\n",
    "        sig_rev_active = (df['RSI'] < 45).astype(int)\n",
    "        \n",
    "        # Store in a dict for easy access\n",
    "        candidates = {\n",
    "            'Trend_Aggro': sig_trend_aggro,\n",
    "            'Trend_Defense': sig_trend_def,\n",
    "            'Rev_Deep': sig_rev_deep,\n",
    "            'Rev_Active': sig_rev_active\n",
    "        }\n",
    "        \n",
    "        # --- 3. Walk-Forward Optimization Loop ---\n",
    "        df['Signal'] = 0.0\n",
    "        df['Selected_Profile'] = 'None' # For debugging/analysis\n",
    "        \n",
    "        lookback = 252       # 1 Year Lookback for Optimization\n",
    "        rebalance_freq = 63  # Quarterly Re-optimization\n",
    "        \n",
    "        indices = df.index\n",
    "        daily_returns = df['Returns']\n",
    "        \n",
    "        if len(df) > lookback:\n",
    "            for t in range(lookback, len(df), rebalance_freq):\n",
    "                train_start = indices[t - lookback]\n",
    "                train_end = indices[t]\n",
    "                test_end_idx = min(t + rebalance_freq, len(df))\n",
    "                test_end = indices[test_end_idx - 1]\n",
    "                \n",
    "                # The Tournament: Check Sharpe of each candidate in lookback period\n",
    "                best_score = -999\n",
    "                best_profile = 'Trend_Defense' # Default safety\n",
    "                \n",
    "                lb_returns = daily_returns.loc[train_start:train_end]\n",
    "                \n",
    "                for name, sig_series in candidates.items():\n",
    "                    # Simulate Strategy Return in Lookback\n",
    "                    # Lag signal by 1 to avoid lookahead in backtest\n",
    "                    sigs = sig_series.loc[train_start:train_end].shift(1).fillna(0)\n",
    "                    strat_ret = lb_returns * sigs\n",
    "                    \n",
    "                    # Calculate Metric (Sharpe)\n",
    "                    mean_ret = strat_ret.mean()\n",
    "                    std_ret = strat_ret.std()\n",
    "                    \n",
    "                    if std_ret > 1e-6:\n",
    "                        score = mean_ret / std_ret # Simple Sharpe\n",
    "                    else:\n",
    "                        score = -999 # Flat line is bad\n",
    "                        \n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_profile = name\n",
    "                \n",
    "                # Apply Best Profile to Next Window (Test Set)\n",
    "                # We use the signal series for the *future* window based on the *past* winner\n",
    "                winner_signals = candidates[best_profile].loc[train_end:test_end]\n",
    "                df.loc[train_end:test_end, 'Signal'] = winner_signals\n",
    "                df.loc[train_end:test_end, 'Selected_Profile'] = best_profile\n",
    "\n",
    "        # --- 4. Volatility Targeting (Risk Management) ---\n",
    "        target_vol = 0.15 / np.sqrt(252)\n",
    "        vol_scaler = (target_vol / df['Volatility']).clip(upper=1.5)\n",
    "        \n",
    "        df['Signal'] = df['Signal'] * vol_scaler\n",
    "        self.data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f9598e",
   "metadata": {},
   "source": [
    "## 5. ROBUST BENCHMARK INFRASTRUCTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "285c817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustBenchmark:\n",
    "    \"\"\"\n",
    "    Implements Walk-Forward Analysis and Deflated Sharpe Ratio logic.\n",
    "    Benchmarks multiple strategies without look-ahead bias[cite: 275].\n",
    "    \"\"\"\n",
    "    def __init__(self, tickers, start_date, end_date):\n",
    "        self.tickers = tickers\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.results = []\n",
    "\n",
    "    def run(self):\n",
    "        print(f\"{'STRATEGY':<10} | {'TICKER':<6} | {'ANN RET':<7} | {'SHARPE':<6} | {'MAX DD':<7} | {'NOTES'}\")\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        strategies = {\n",
    "            \"V1_Base\": StrategyV1_Baseline,\n",
    "            \"V2_GMM\": StrategyV2_Advanced,\n",
    "            \"V3_Macro\": StrategyV3_Macro,\n",
    "            \"V4_Meta\": StrategyV4_Meta,\n",
    "            \"V5_Kalman\": StrategyV5_KalmanState,\n",
    "            \"V6_Inst\": StrategyV6_MetaLabeling,\n",
    "            \"V7_Optim\": StrategyV7_AdaptiveOptim\n",
    "        }\n",
    "\n",
    "        for ticker in self.tickers:\n",
    "            # Capture Buy & Hold first\n",
    "            bh = StrategyV1_Baseline(ticker, self.start_date, self.end_date)\n",
    "            bh.fetch_data()\n",
    "            bh.data['Signal'] = 1 # Force Buy\n",
    "            bh.run_backtest()\n",
    "            self._print_row(\"Buy&Hold\", ticker, bh.metrics)\n",
    "            \n",
    "            for name, StratClass in strategies.items():\n",
    "                try:\n",
    "                    strat = StratClass(ticker, self.start_date, self.end_date)\n",
    "                    strat.fetch_data(warmup_years=2)\n",
    "                    strat.generate_signals()\n",
    "                    strat.run_backtest()\n",
    "                    \n",
    "                    self._print_row(name, ticker, strat.metrics)\n",
    "                    \n",
    "                    # Store for portfolio level (optional)\n",
    "                    self.results.append({\n",
    "                        'Ticker': ticker,\n",
    "                        'Strategy': name,\n",
    "                        'Returns': strat.results['Net_Returns']\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed {name} {ticker}: {e}\")\n",
    "            print(\"-\" * 75)\n",
    "\n",
    "    def _print_row(self, name, ticker, metrics):\n",
    "        if not metrics: return\n",
    "        ret = metrics['Total Return']\n",
    "        # Annualize return approx\n",
    "        ann_ret = (1 + ret) ** (252 / len(metrics.get('Returns', [1]*252))) - 1 if 'Returns' in metrics else ret\n",
    "        print(f\"{name:<10} | {ticker:<6} | {ret:.1%}   | {metrics['Sharpe Ratio']:.2f}   | {metrics['Max Drawdown']:.1%}   |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c992984",
   "metadata": {},
   "source": [
    "## 6. EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd7744c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRATEGY   | TICKER | ANN RET | SHARPE | MAX DD  | NOTES\n",
      "---------------------------------------------------------------------------\n",
      "Buy&Hold   | NVDA   | 946.9%   | 1.38   | -66.3%   |\n",
      "V1_Base    | NVDA   | 50.0%   | 1.19   | -6.9%   |\n",
      "V2_GMM     | NVDA   | 100.7%   | 1.17   | -10.9%   |\n",
      "V3_Macro   | NVDA   | 357.9%   | 1.61   | -25.6%   |\n",
      "V4_Meta    | NVDA   | 354.4%   | 1.63   | -23.8%   |\n",
      "V5_Kalman  | NVDA   | 149.7%   | 1.18   | -20.5%   |\n",
      "V6_Inst    | NVDA   | 152.7%   | 1.04   | -25.5%   |\n",
      "V7_Optim   | NVDA   | 144.0%   | 1.20   | -14.3%   |\n",
      "---------------------------------------------------------------------------\n",
      "Buy&Hold   | SPY    | 70.7%   | 0.90   | -24.5%   |\n",
      "V1_Base    | SPY    | 94.6%   | 1.06   | -20.2%   |\n",
      "V2_GMM     | SPY    | 14.9%   | 0.37   | -18.9%   |\n",
      "V3_Macro   | SPY    | 94.7%   | 1.11   | -25.6%   |\n",
      "V4_Meta    | SPY    | 32.0%   | 0.55   | -17.7%   |\n",
      "V5_Kalman  | SPY    | 70.4%   | 1.07   | -18.3%   |\n",
      "V6_Inst    | SPY    | 83.7%   | 0.89   | -28.6%   |\n",
      "V7_Optim   | SPY    | 0.5%   | 0.08   | -28.3%   |\n",
      "---------------------------------------------------------------------------\n",
      "Buy&Hold   | JPM    | 113.5%   | 0.91   | -38.8%   |\n",
      "V1_Base    | JPM    | 85.3%   | 0.92   | -27.6%   |\n",
      "V2_GMM     | JPM    | 16.8%   | 0.34   | -17.3%   |\n",
      "V3_Macro   | JPM    | 110.5%   | 0.98   | -31.5%   |\n",
      "V4_Meta    | JPM    | 102.6%   | 1.03   | -21.7%   |\n",
      "V5_Kalman  | JPM    | 6.4%   | 0.18   | -36.7%   |\n",
      "V6_Inst    | JPM    | 32.1%   | 0.44   | -26.6%   |\n",
      "V7_Optim   | JPM    | 45.4%   | 0.87   | -12.7%   |\n",
      "---------------------------------------------------------------------------\n",
      "Buy&Hold   | BABA   | -61.4%   | -0.21   | -76.7%   |\n",
      "V1_Base    | BABA   | 42.8%   | 0.80   | -9.8%   |\n",
      "V2_GMM     | BABA   | -5.8%   | -0.04   | -29.4%   |\n",
      "V3_Macro   | BABA   | -26.4%   | -0.33   | -45.4%   |\n",
      "V4_Meta    | BABA   | -17.6%   | -0.21   | -33.4%   |\n",
      "V5_Kalman  | BABA   | -26.2%   | -0.59   | -40.4%   |\n",
      "V6_Inst    | BABA   | -22.3%   | -0.42   | -36.3%   |\n",
      "V7_Optim   | BABA   | -21.5%   | -0.38   | -31.2%   |\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "bench = RobustBenchmark(\n",
    "    tickers=[\"NVDA\", \"SPY\", \"JPM\", \"BABA\"], \n",
    "    start_date=\"2021-01-01\", \n",
    "    end_date=\"2024-12-30\"\n",
    ")\n",
    "bench.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
